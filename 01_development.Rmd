---
title: "01_development"
author: "Darren Norris"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_depth: 3
    fig_caption: yes
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    number_sections: yes
    extra_dependencies: flafter
    highlight: tango
    includes:
      in_header: preamble.txe
always_allow_html: yes
urlcolor: blue
toc-title: Contents
header-includes:
  - \counterwithin{figure}{section}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE, collapse = TRUE,
  comment = "#>" 
  )
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}", collapse = "\n"))
})
```

\newpage{}

# Load and prep data
## Packages
```{r load-packages, warning=FALSE, message=FALSE}
library(plyr) # plyr before tidyverse
library(tidyverse)
library(stringr)
library(readxl)
library(gridExtra)
library(magrittr)
```

## Journal impact

[Scopus CiteScore](https://www.elsevier.com/solutions/scopus/how-scopus-works/metrics/citescore) and [JCR Journal Impact Factor ("JIF")](https://clarivate.com/webofsciencegroup/solutions/journal-citation-reports/), downloaded on 24 and 23 January 2023 respectively. 
Using 11 years (2011 to 2021), as 2011 was first year for CiteScore, the year when Altmetrics was founded and also follows the definition of conservation threats and actions published in 2008 (Salafsky et. al., 2008 A Standard Lexicon for Biodiversity Conservation: Unified Classifications of Threats and Actions https://doi.org/10.1111/j.1523-1739.2008.00937.x). 
The companies classify journals differently and the folder [data](https://github.com/darrennorris/hey-jude/tree/main/data) has JCR impact of  Biodiversity Conservation category journals (JIF https://github.com/darrennorris/hey-jude/tree/main/data/clarivate_JCR) and matching CiteScore (CiteScore: https://github.com/darrennorris/hey-jude/tree/main/data/scopus_citescore). To match, CiteScore comes from a combination of journals in "Nature and Landscape Conservation", "Ecology, Evolution, Behavior and Systematics" and  the following 12:
African Natural History, Proceedings Of The Linnean Society Of New South Wales, Caribbean Journal Of Science, Urban Ecosystems, Natural History, Revista Chilena De Historia Natural, Polar Biology, Pachyderm, Global Change Biology, Bulletin Of The American Museum Of Natural History, American Museum Novitates, Journal Of Applied Ecology. 


Code below loads and joins CiteScore to JIF. 
```{r load-journal-impact}
jcr_11a21 <-read_excel("data/clarivate_JCR/JCR2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(Journal_name = if_else(Journal_name =="Eco mont-Journal on Protected Mountain Areas Research", "Eco.mont", 
          Journal_name)) %>%
  mutate(name_join = str_to_upper(str_replace_all(Journal_name, "[:punct:]", "")))
cs_NLC_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(SourceTitle = if_else(SourceTitle=="Natureza a Conservacao", "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))
# conservation and ecology
cs_NLCECO_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_ECO_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>%
  #drop structural NAs
  filter(!is.na(CiteScore)) %>% 
    mutate(SourceTitle = if_else(SourceTitle %in% c("Natureza a Conservacao"), 
                                 "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))

jcr_11a21 %>% left_join(cs_NLCECO_11a21, 
                        by = c("ayear"="ayear", 
                               "name_join" = "name_join")) -> journals_11a21
# 12 journals. Differences due to differences in journals and coverage years 
# between databases used to calculate JCR JIF and Scopus CiteScore.
journals_11a21 %>% 
  group_by(Journal_name, name_join) %>% summarise(count_na = sum(is.na(CiteScore))) %>% 
    filter(count_na >0) %>%
  arrange(desc(count_na)) %>% data.frame


```

Calculate descriptive summaries.
```{r journal-impact-summaries, message=FALSE, warning=FALSE}
study_years <- c(2011:2021)
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
  filter(!is.na(value)) %>%
  group_by(ayear, indicator) %>% 
  summarise(journal_count = length(unique(name_join)),
            journal_impact = median(value),
            lq = quantile(value, probs=0.025), 
            uq = quantile(value, probs=0.975)) %>% 
    ungroup() -> journals_11a21_sum
# start and end values over time
count_years <- length(unique(journals_11a21_sum$ayear))
start_year <- min(journals_11a21_sum$ayear)
end_year <- max(journals_11a21_sum$ayear)
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_impact) -> start_JIF
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_count) -> start_count
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_impact) -> end_JIF
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_count) -> end_count

```

Temporal trends in journals. The number of JCR Biodiversity Conservation journals increased from `r start_count` to `r end_count` over  `r count_years` years.

Plot to check patterns in journal impact.
```{r plot-journals-year, out.width="70%", out.height="70%", fig.cap= "Trends in indicators of impacts across conservaiton journals."}
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
    filter(!is.na(value)) %>%
  ggplot(aes(x=ayear, y=value)) + 
  geom_point() + 
  geom_boxplot() +
  facet_wrap(~indicator, nrow = 2, scales = "free_y")
```


Plot to check. Median impact and number of journals per year.
```{r plot-journals-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in journal number and indicators of impact across conservaiton journals. Points are median values with verticle lines showing 95% interval of value ranges (0.025 - 0.975 quantile range)."}
journals_11a21_sum %>%
  # use group = 1 so lines go through year which is a factor
  ggplot(aes(x=ayear, y=journal_impact, group=1)) + 
  geom_line(colour="blue", linewidth=1) +
  geom_errorbar(aes(ymin=lq, ymax=uq), width=.1) +
  geom_point(aes(size=journal_count)) + 
  scale_size_continuous("journal\ncount") +
  facet_wrap(~indicator, nrow = 2, scales = "free_y") + 
  labs(x="year", 
       y="impact indicator value")
```
## Literature search checking

Load bibliometric packages.
```{r load-packages-bibliometrics, message=FALSE, warning=FALSE}
library(bibliometrix)
library(rcrossref)
library(rAltmetric)
library(metagear)

```


Load bibliographic data from WOS core collection.
```{r load-search, eval=FALSE}
# 1) helper functions
# file names
source("R/get_files.R")
# load files
source("R/load_bib.R")
# hack bibliometrix::mergeDbSources to work with list object
source("R/mergeDbSourcesDN.R")

# 2) import and create bibliografic data.frame
infolder <- "data/wos_20230130/"
df_files_wos <- get_files(folder_name = infolder)
lwos <- plyr::alply(df_files_wos, .margins = 1, .fun = load_bib)
# 16795 ( 1 duplicate removed)
wosDN <- mergeDbSourcesDN(lwos, remove.duplicated=TRUE)
saveRDS(wosDN, "data/wosDN.rds")
rm("lwos")
rm("wosDN")

```


### Screening

Screening showed that 24% (48/200) of articles did not meet inclusion criteria (not vertebrates e.g. MAXENT, plants/invertebrates, metaanalysis, review, laboratory).
Screening 100 takes approximately 25 minutes. Screening 16000 would take approximately 67 
hours.
```{r screen-search, eval=FALSE}
wosDN <- readRDS("data/wosDN.rds")
wosDN  %>% 
  filter(!is.na(AB), !is.na(TI)) %>% 
  slice_sample(n=200) -> screen_wos 
screen_wos  %>% 
  #to help use with metagear
  mutate(STUDY_ID = row_number()) -> screen_meta    

#Metagear. Prep to screen to retain only relevant studies
screen_meta %>% mutate(AUTHORS = AU, YEAR = PY, TITLE = TI, 
                    JOURNAL = SO, VOLUME = VL, LPAGES = PP, UPAGES = PP, 
                    DOI = DI, ABSTRACT = AB) %>% 
  select(STUDY_ID, AUTHORS, YEAR, TITLE, JOURNAL, VOLUME, LPAGES, 
         UPAGES, DOI, ABSTRACT) -> screen_metagear

screen_meta_ini <- effort_initialize(screen_metagear, study_ID = FALSE)
theTeam <- c("Darren", "noone")
theRefs_unscreened <- effort_distribute(screen_meta_ini, 
                                        reviewers = theTeam, 
                                        initialize = TRUE,
                                        effort = c(50, 50), 
                                        save_split = TRUE)

abstract_screener("effort_noone1.csv", aReviewer = "noone")

```


## Literature search results

Add altmetrics. To complete.
```{r add-altmetrics, eval=FALSE}
# Politely import altmetrics. "rAltmetrics" retired. "dimensionsR" active.
# 1) helper functions
source("R/altmetrics_updated.R")
source("R/safe_altmetrics.R")
source("R/get_altm.R")

# 2) get altmetrics
wosDN <- readRDS("data/wosDN.rds")

# split to avoid API and internet connection issues
alt01 <- plyr::adply(wosDN[1:500, ], .margins = 1, .fun = get_altm)
alt02 <- plyr::adply(wosDN[501:1000, ], .margins = 1, .fun = get_altm)
alt03 <- plyr::adply(wosDN[1001:2000, ], .margins = 1, .fun = get_altm)
alt04 <- plyr::adply(wosDN[2001:3000, ], .margins = 1, .fun = get_altm)
alt05 <- plyr::adply(wosDN[3001:4000, ], .margins = 1, .fun = get_altm)
alt06 <- plyr::adply(wosDN[4001:5000, ], .margins = 1, .fun = get_altm)
alt07 <- plyr::adply(wosDN[5001:6000, ], .margins = 1, .fun = get_altm)
alt08 <- plyr::adply(wosDN[6001:7000, ], .margins = 1, .fun = get_altm)
alt09 <- plyr::adply(wosDN[7001:8000, ], .margins = 1, .fun = get_altm)
alt10 <- plyr::adply(wosDN[8001:9000, ], .margins = 1, .fun = get_altm)
alt11 <- plyr::adply(wosDN[9001:10000, ], .margins = 1, .fun = get_altm)
alt12 <- plyr::adply(wosDN[10001:11000, ], .margins = 1, .fun = get_altm)
alt13 <- plyr::adply(wosDN[11001:12000, ], .margins = 1, .fun = get_altm)
alt14 <- plyr::adply(wosDN[12001:13000, ], .margins = 1, .fun = get_altm)
alt15 <- plyr::adply(wosDN[13001:14000, ], .margins = 1, .fun = get_altm)
alt16 <- plyr::adply(wosDN[14001:15000, ], .margins = 1, .fun = get_altm)
alt17 <- plyr::adply(wosDN[15001:16000, ], .margins = 1, .fun = get_altm)
alt18 <- plyr::adply(wosDN[16001:16795, ], .margins = 1, .fun = get_altm)
# Results for all 16795
alt_all <- rbind(alt01, alt02, alt03, alt04, alt05, alt06, alt07, alt08, alt09, alt10, 
             alt11, alt12, alt13, alt14, alt15, alt16, alt17, alt18)
#Export for future use.
saveRDS(alt_all, "data/alt_all.rds")
rm("alt_all")
```


Check missing Altmetric values.
```{r missing-altmetric, eval=FALSE}
alt_all <- readRDS("data/alt_all.rds")
alt_all %>% 
  filter(is.na(altmetric)) %>% 
  select(!c(altmetric, altmetric_3m)) -> alt_na #4359
altna_01 <- plyr::adply(alt_na[1:200, ], .margins = 1, .fun = get_altm)
altna_02 <- plyr::adply(alt_na[201:400, ], .margins = 1, .fun = get_altm)
altna_03 <- plyr::adply(alt_na[401:600, ], .margins = 1, .fun = get_altm)
altna_04 <- plyr::adply(alt_na[601:800, ], .margins = 1, .fun = get_altm)
altna_05 <- plyr::adply(alt_na[801:1000, ], .margins = 1, .fun = get_altm)
altna_all <- rbind(altna_01, altna_02, altna_03, altna_04, altna_05)

altna_all %>% 
  filter(!is.na(altmetric)) # 0 all NAs second time as well
saveRDS(altna_all, "data/altna_all.rds")
```


Calculate summaries of articles.
```{r article-summaries}
# bibliometrix data.frame has the following
# AB =  Abstract, DI = doi, SO = journal title, TC = times cited, 
# TI = article title, PY = publication year 
wosDN <- readRDS("data/wosDN.rds")
wosDN %>% 
  filter(PY %in% study_years) %>% 
  group_by(PY) %>% summarise(count_articles = n()) -> article_summary
# start and end values over time
count_years_articles <- length(unique(article_summary$PY))
start_year_articles <- min(article_summary$PY)
end_year_articles <- max(article_summary$PY)

start_count_articles <- article_summary %>% filter(PY==start_year_articles) %>% 
  pull(count_articles)
end_count_articles <- article_summary %>% filter(PY==end_year_articles) %>% 
  pull(count_articles)

```


Temporal trends in article count of vertebrate studies. 
The number of articles published per year in JCR Biodiversity Conservation journals more than doubled from `r start_count_articles` to `r end_count_articles` over  `r count_years_articles` years.
```{r plot-articles-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in article number across conservaiton journals. Points show published articles per year. Dashed line predictions from GLM (poisson family) and shaded areas 95% CI to aid visual interpretation."}
# use 2011 - 2021. Update with 2022 articles after May 2023.
article_summary %>% 
  ggplot(aes(x=PY, y=count_articles)) + 
  geom_point() + 
  stat_smooth(method = "glm", method.args = list(family = 'poisson'), 
              linetype = "dashed") +
  labs(x="year", 
       y="article count")
```


# Sentiment analysis

May need to also use custom classifier (e.g. Twitter optimism https://doi.org/10.1098/rsos.190473), machine learning available via [superml](https://github.com/saraswatmks/superml).

Human annotated classification avalable for tweets: 
https://doi.org/10.1371/journal.pone.0155036 (https://www.clarin.si/repository/xmlui/handle/11356/1054)

Download tweets via https://cran.r-project.org/web/packages/rehydratoR/rehydratoR.pdf

API key: g6IwJTpYXHGRFj2M9rhfcljE2
API Key Secret  cvSWp2ccBKFJFJ5K1lUUxnaoJgpupxP91HVtwrI3lojHWV9sXK
```{r test-sentiment, eval=FALSE}
library(sentimentr)
alt_all <- readRDS("data/alt_all.rds")

# Test on an optimistic example
doi_positive <- "10.1016/j.biocon.2019.02.022"
alt_all %>% 
  filter(DI==doi_positive) %>% pull(AB) -> abstract_positive

mytext <- sentimentr::get_sentences(abstract_positive)
sentiment(mytext)

# Abstracts
alt_all[1:6, ] %>% 
  filter(!is.na(AB), !is.na(DI)) %>%
    get_sentences() %$%
    sentiment_by(AB, list(DI))

#171298 sentances
alt_all %>% 
  filter(!is.na(AB), !is.na(DI)) %>% 
  select(DI, AB) %>%
    dplyr::mutate(ab_split = get_sentences(AB)) %>% 
  unnest_longer(ab_split) -> abstract_sentances

saveRDS(abstract_sentances, "data/abstract_sentances.rds")
abstract_sentances %$%
    sentiment_by(ab_split) -> abstract_sentances_sentiment
bind_cols(abstract_sentances, abstract_sentances_sentiment) -> ab_sent_senti
ab_sent_senti %>% 
  group_by(DI, AB) %>% 
  summarise(ab_word_count = sum(word_count), 
            ab_sentance_count = n(), 
            ab_sentiment_min = round(min(ave_sentiment),4), 
            ab_sentiment_max = round(max(ave_sentiment),4), 
            ab_sentiment_med = round(median(ave_sentiment),3),
            ab_sentiment_sd = round(sd(ave_sentiment),3)) -> ab_sent_senti
saveRDS(ab_sent_senti, "data/ab_sent_senti.rds")

# Titles
#recommended process flow, but uncombine adds duplicate rows dont use.
#alt_all[1:6, ] %>%
#    get_sentences() %$%
#    sentiment_by(TI, list(AU, PY, DI)) -> title_sent
#uncombine(title_sent)

alt_all %>% 
  filter(!is.na(TI), !is.na(DI)) %>% 
  select(DI, TI) %>%
    dplyr::mutate(title_split = get_sentences(TI)) %>% 
  unnest_longer(title_split) -> title_sentances

title_sentances %$%
    sentiment_by(title_split) -> title_sentances_sentiment

bind_cols(title_sentances, title_sentances_sentiment) -> title_sent_senti
title_sent_senti %>% 
  group_by(DI, TI) %>% 
  summarise(ti_word_count = sum(word_count), 
            ti_sentance_count = n(), 
            ti_sentiment_min = round(min(ave_sentiment),4), 
            ti_sentiment_max = round(max(ave_sentiment),4), 
            ti_sentiment_med = round(median(ave_sentiment),3),
            ti_sentiment_sd = round(sd(ave_sentiment),3)) -> ti_sent_senti
saveRDS(title_sent_senti, "data/title_sent_senti.rds")

# join sentiment to articles
alt_all %>% 
  left_join(ab_sent_senti) %>% 
  left_join(ti_sent_senti) -> all_alti_senti

# Export for future use
saveRDS(all_alti_senti, "data/all_alti_senti.RDS")
write.csv(all_alti_senti, "data/all_alti_senti.csv")
rm("abstract_sentances")
rm("abstract_sentances_sentiment")
rm("ab_sent_senti")
rm("title_sentances")
rm("title_sentances_sentiment")
rm(ti_sent_senti)
rm(alt_all)
rm(alt_na)

```


Summaries of sentiment.
```{r abstract-sentiment-summary}
# check for differences in counts of journal names. Same journal changes name etc?
# Need to standardize journal names in WOS search results.
all_alti_senti <- readRDS("data/all_alti_senti.RDS")
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(SO) %>% 
  unique() %>% length() -> journal_count_ab # 81
jcr_11a21 %>% 
  filter(ayear %in% study_years) %>% pull(Journal_name) %>% 
  unique() %>% length() -> journal_count_jcr # 73
jcr_11a21 %>% 
  filter(ayear %in% study_years) %>% pull(ISSN) %>% 
  unique() %>% length() -> journal_count_issn # 69

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(DI) %>% 
  unique() %>% length() #14330

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(DI) %>% 
  unique() %>% length() -> article_count_doi#14330

all_alti_senti %>%
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric),PY %in% study_years) %>% 
  pull(DI) %>% 
  unique() %>% length() # 10395
all_alti_senti %>%
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), 
         !is.na(TC),PY %in% study_years) %>% 
  pull(DI) %>% 
  unique() %>% length() # 10395
```
Correlation.
```{r sentiment-correlation}
df1a1 <- data.frame(ab_sentiment_med = seq(-2,2), ti_sentiment_med = seq(-2,2))

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>%
  ggplot(aes(x=ab_sentiment_med, y=ti_sentiment_med)) +
  geom_point() + 
  geom_line(data= df1a1, aes(x=ab_sentiment_med, y=ti_sentiment_med)) +
  stat_smooth(method="lm", linetype="dashed") + 
  coord_fixed(xlim=c(-1,1), ylim=c(-1.6, 1.4)) +
  labs(x="Abstract sentiment", y="Title sentiment")

```


Plot to see/explore. Temporal trrends in abstract and title sentiment.
```{r plot-sentiment-year, fig.height=5, fig.width=7}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
    select(PY, altmetric, TC, ab_sentiment_med, ti_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(ab_sentiment_med, ti_sentiment_med)) %>% 
  mutate(name = if_else(name=="ab_sentiment_med", "abstract sentiment", 
                        "title sentiment")) %>%
  ggplot(aes(x=factor(PY), y=value)) + 
  geom_point() + 
  geom_violin(draw_quantiles = 0.5) + 
  coord_flip() + 
  facet_wrap(~name) +
  labs(x="year", y="sentiment")
```

Relationship between article impact and Abstract sentiment.

```{r plot-article-impact-sentiment, fig.height=6, fig.width=5}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
  select(PY, altmetric, TC, ab_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(altmetric, TC)) %>% 
  mutate(name = if_else(name=="TC", "times cited", name)) %>%
  ggplot(aes(x=value, y = ab_sentiment_med)) + 
  geom_point() + 
  geom_smooth(method = "gam")+
  facet_grid(year~name, scales = "free_x") + 
  labs(x="article impact", y="Abstract sentiment")
```


Relationship between article impact and title sentiment.

```{r plot-title-impact-sentiment, fig.height=6, fig.width=5}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
  select(PY, altmetric, TC, ti_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(altmetric, TC)) %>% 
  mutate(name = if_else(name=="TC", "times cited", name)) %>%
  ggplot(aes(x=value, y = ti_sentiment_med)) + 
  geom_point() + 
  geom_smooth(method = "gam")+
  facet_grid(year~name, scales = "free_x") + 
  labs(x="article impact", y="title sentiment")
```

Trim extreme values (Zuur 2010  https://doi.org/10.1111/j.2041-210X.2009.00001.x)? Do article impact indicators and sentiment values have 
extreme values?

Citations per year and title sentiment.
```{r plot-citations-per-year, fig.width=7, fig.height=12}
# citations per year
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>%
  arrange(cite_per_year) %>% 
  mutate(cite_order = row_number()) %>% 
  ggplot(aes(x=cite_per_year, y=cite_order)) + 
  geom_jitter(width=3, aes(col=ti_sentiment_med), alpha=0.3, size=2) + 
  scale_colour_gradient2("title\nsentiment", 
                         low = "red", mid = "grey80", high = "green") +
  facet_wrap(~PY, scales = "free", ncol = 2) + 
  labs(title = "(A)", y="order of times cited per year", 
       x = "times cited per year") + 
  theme_bw()
```

Citations per year and abstract sentiment.
```{r plot-citations-per-year-abstract, fig.width=7, fig.height=12}
# citations per year
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>%
  arrange(cite_per_year) %>% 
  mutate(cite_order = row_number()) %>% 
  ggplot(aes(x=cite_per_year, y=cite_order)) + 
  geom_jitter(width=3, aes(col=ab_sentiment_med), alpha=0.3, size=2) + 
  scale_colour_gradient2("abstract\nsentiment", 
                         low = "red", mid = "grey80", high = "green") +
  facet_wrap(~PY, scales = "free", ncol = 2) + 
  labs(title = "(A)", y="order of times cited per year", 
       x = "times cited per year") + 
  theme_bw()
```


Explore data with Cleveland plots.


```{r cleveland-plot-citation, fig.width=8, fig.height=12}
# Okabe-Ito colour blind safe
okabe <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>% 
#  pull(cite_per_year) %>% summary() 
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  0.000   1.500   3.000   4.351   5.444 158.000 
  arrange(cite_per_year) %>%
  mutate(cite_rank = rank(cite_per_year), 
         cite_order = row_number(),
         flag_sentiment = case_when(ab_sentiment_min<0 & ab_sentiment_med<0 ~ "negative", 
                                    ab_sentiment_min>0 & ab_sentiment_med>0 ~ "positive", 
                                    TRUE ~"neutral") 
         ) %>% 
  ggplot(aes(x=altmetric, y=cite_per_year)) + 
  geom_jitter(aes(colour=flag_sentiment), height=1, alpha=0.4) +
  stat_smooth(aes(colour=flag_sentiment), method = "gam", se=FALSE) +
  scale_colour_manual("abstract\nsentiment", 
                      values = c("#E69F00", "grey70", "#009E73")) + 
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(A)", y="times cited per year", 
       x = "altimetric") + 
  theme_bw() + theme(legend.position="top") + 
  guides(color = guide_legend(nrow = 2)) -> fig_citation


all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  arrange(TC) %>% 
  mutate(ti_order = rank(ti_sentiment_med)) %>% 
  ggplot(aes(x=ab_sentiment_med, y=ti_order)) + 
  geom_point(aes(colour=TC)) + 
  scale_color_viridis_c("times\ncited", trans = "log1p") +
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(B)", x="abstract sentiment", 
       y="rank title sentiment") + theme(legend.position="top") -> fig_sent_cite

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  arrange(altmetric) %>% 
  mutate(ti_order = rank(ti_sentiment_med)) %>% 
  ggplot(aes(x=ab_sentiment_med, y=ti_order)) + 
  geom_point(aes(colour=altmetric)) + 
  scale_color_viridis_c("altmetric", trans = "log1p") +
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(C)", x="abstract sentiment", 
       y="rank title sentiment") + theme(legend.position="top") -> fig_sent_alt


gridExtra::grid.arrange(fig_citation, fig_sent_cite, fig_sent_alt, nrow=1)

```


Tidy to keep workspace small.
```{r tidy-workspace}
rm(fig_citation)
rm(fig_sent_alt)
rm(fig_sent_cite)
```

