---
title: "01_development"
author: "Darren Norris"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_depth: 3
    fig_caption: yes
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    number_sections: yes
    extra_dependencies: flafter
    highlight: tango
    includes:
      in_header: preamble.txe
always_allow_html: yes
urlcolor: blue
toc-title: Contents
header-includes:
  - \counterwithin{figure}{section}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE, collapse = TRUE,
  comment = "#>" 
  )
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}", collapse = "\n"))
})
```

\newpage{}

# Load and prep data
## Packages
```{r load-packages, warning=FALSE, message=FALSE}
library(plyr) # plyr b4 tidyverse
library(tidyverse)
library(stringr)
library(readxl)
library(gridExtra)
library(magrittr)
```

## Journal impact

[Scopus CiteScore](https://www.elsevier.com/solutions/scopus/how-scopus-works/metrics/citescore) and [JCR Journal Impact Factor ("JIF")](https://clarivate.com/webofsciencegroup/solutions/journal-citation-reports/), downloaded on 24 and 23 January 2023 respectively. 
Using 11 years (2011 to 2021), as 2011 was first year for CiteScore, the year when Altmetrics was founded and also follows the definition of conservation threats and actions published in 2008 (Salafsky et. al., 2008 A Standard Lexicon for Biodiversity Conservation: Unified Classifications of Threats and Actions https://doi.org/10.1111/j.1523-1739.2008.00937.x). 
The companies classify journals differently and the folder [data](https://github.com/darrennorris/hey-jude/tree/main/data) has JCR impact of  Biodiversity Conservation category journals (JIF https://github.com/darrennorris/hey-jude/tree/main/data/clarivate_JCR) and matching CiteScore (CiteScore: https://github.com/darrennorris/hey-jude/tree/main/data/scopus_citescore). To match, CiteScore comes from a combination of journals in "Nature and Landscape Conservation", "Ecology, Evolution, Behavior and Systematics" and  the following 12:
African Natural History, Proceedings Of The Linnean Society Of New South Wales, Caribbean Journal Of Science, Urban Ecosystems, Natural History, Revista Chilena De Historia Natural, Polar Biology, Pachyderm, Global Change Biology, Bulletin Of The American Museum Of Natural History, American Museum Novitates, Journal Of Applied Ecology. 


Code below loads and joins CiteScore to JIF. 
```{r load-journal-impact}
jcr_11a21 <-read_excel("data/clarivate_JCR/JCR2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(Journal_name = if_else(Journal_name =="Eco mont-Journal on Protected Mountain Areas Research", "Eco.mont", 
          Journal_name)) %>%
  mutate(name_join = str_to_upper(str_replace_all(Journal_name, "[:punct:]", "")))
cs_NLC_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(SourceTitle = if_else(SourceTitle=="Natureza a Conservacao", "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))
# conservation and ecology
cs_NLCECO_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_ECO_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>%
  #drop structural NAs
  filter(!is.na(CiteScore)) %>% 
    mutate(SourceTitle = if_else(SourceTitle %in% c("Natureza a Conservacao"), 
                                 "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))

jcr_11a21 %>% left_join(cs_NLCECO_11a21, 
                        by = c("ayear"="ayear", 
                               "name_join" = "name_join")) -> journals_11a21
# 12 journals. Differences due to differences in journals and coverage years 
# between databases used to calculate JCR JIF and Scopus CiteScore.
journals_11a21 %>% 
  group_by(Journal_name, name_join) %>% summarise(count_na = sum(is.na(CiteScore))) %>% 
    filter(count_na >0) %>%
  arrange(desc(count_na)) %>% data.frame


```

Calculate descriptive summaries.
```{r journal-impact-summaries, message=FALSE, warning=FALSE}
study_years <- c(2011:2021)
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
  filter(!is.na(value)) %>%
  group_by(ayear, indicator) %>% 
  summarise(journal_count = length(unique(name_join)),
            journal_impact = median(value),
            lq = quantile(value, probs=0.025), 
            uq = quantile(value, probs=0.975)) %>% 
    ungroup() -> journals_11a21_sum
# start and end values over time
count_years <- length(unique(journals_11a21_sum$ayear))
start_year <- min(journals_11a21_sum$ayear)
end_year <- max(journals_11a21_sum$ayear)
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_impact) -> start_JIF
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_count) -> start_count
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_impact) -> end_JIF
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_count) -> end_count

```

Temporal trends in journals. The number of JCR Biodiversity Conservation journals increased from `r start_count` to `r end_count` over  `r count_years` years.

Plot to check patterns in journal impact.
```{r plot-journals-year, out.width="70%", out.height="70%", fig.cap= "Trends in indicators of impacts across conservaiton journals."}
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
    filter(!is.na(value)) %>%
  ggplot(aes(x=ayear, y=value)) + 
  geom_point() + 
  geom_boxplot() +
  facet_wrap(~indicator, nrow = 2, scales = "free_y")
```


Plot to check. Median impact and number of journals per year.
```{r plot-journals-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in journal number and indicators of impact across conservaiton journals. Points are median values with verticle lines showing 95% interval of value ranges (0.025 - 0.975 quantile range)."}
journals_11a21_sum %>%
  # use group = 1 so lines go through year which is a factor
  ggplot(aes(x=ayear, y=journal_impact, group=1)) + 
  geom_line(colour="blue", linewidth=1) +
  geom_errorbar(aes(ymin=lq, ymax=uq), width=.1) +
  geom_point(aes(size=journal_count)) + 
  scale_size_continuous("journal\ncount") +
  facet_wrap(~indicator, nrow = 2, scales = "free_y") + 
  labs(x="year", 
       y="impact indicator value")
```

## Literature search results

Load bibliometric packages.
```{r load-packages-bibliometrics, message=FALSE, warning=FALSE}
library(bibliometrix)
library(rcrossref)
library(rAltmetric)
library(metagear)

```


Load bibliographic data from WOS core collection.
```{r load-search, message=FALSE, warning=FALSE, eval=FALSE}
# 1) helper functions
# file names
source("R/get_files.R")
# load files
source("R/load_bib.R")
# hack bibliometrix::mergeDbSources to work with list object
source("R/mergeDbSourcesDN.R")

# 2) import and create bibliografic data.frame
infolder <- "data/wos_20230130/"
df_files_wos <- get_files(folder_name = infolder)
lwos <- plyr::alply(df_files_wos, .margins = 1, .fun = load_bib)
# 16795 ( 1 duplicate removed)
wosDN <- mergeDbSourcesDN(lwos, remove.duplicated=TRUE)
saveRDS(wosDN, "data/wosDN.rds")
rm("lwos")
rm("wosDN")

```

Add altmetrics. To complete.
```{r add-altmetrics, eval=FALSE}
# Politely import altmetrics. "rAltmetrics" retired. "dimensionsR" active.
# 1) helper functions
source("R/altmetrics_updated.R")
source("R/safe_altmetrics.R")
source("R/get_altm.R")

# 2) get altmetrics
wosDN <- readRDS("data/wosDN.rds")

# split to avoid API and internet connection issues
alt01 <- plyr::adply(wosDN[1:500, ], .margins = 1, .fun = get_altm)
alt02 <- plyr::adply(wosDN[501:1000, ], .margins = 1, .fun = get_altm)
alt03 <- plyr::adply(wosDN[1001:2000, ], .margins = 1, .fun = get_altm)
alt04 <- plyr::adply(wosDN[2001:3000, ], .margins = 1, .fun = get_altm)
alt05 <- plyr::adply(wosDN[3001:4000, ], .margins = 1, .fun = get_altm)
alt06 <- plyr::adply(wosDN[4001:5000, ], .margins = 1, .fun = get_altm)
alt07 <- plyr::adply(wosDN[5001:6000, ], .margins = 1, .fun = get_altm)
alt08 <- plyr::adply(wosDN[6001:7000, ], .margins = 1, .fun = get_altm)
alt09 <- plyr::adply(wosDN[7001:8000, ], .margins = 1, .fun = get_altm)
alt10 <- plyr::adply(wosDN[8001:9000, ], .margins = 1, .fun = get_altm)
alt11 <- plyr::adply(wosDN[9001:10000, ], .margins = 1, .fun = get_altm)
alt12 <- plyr::adply(wosDN[10001:11000, ], .margins = 1, .fun = get_altm)
alt13 <- plyr::adply(wosDN[11001:12000, ], .margins = 1, .fun = get_altm)
alt14 <- plyr::adply(wosDN[12001:13000, ], .margins = 1, .fun = get_altm)
alt15 <- plyr::adply(wosDN[13001:14000, ], .margins = 1, .fun = get_altm)
alt16 <- plyr::adply(wosDN[14001:15000, ], .margins = 1, .fun = get_altm)
alt17 <- plyr::adply(wosDN[15001:16000, ], .margins = 1, .fun = get_altm)
alt18 <- plyr::adply(wosDN[16001:16795, ], .margins = 1, .fun = get_altm)
# Results for all 16795
alt_all <- rbind(alt01, alt02, alt03, alt04, alt05, alt06, alt07, alt08, alt09, alt10, 
             alt11, alt12, alt13, alt14, alt15, alt16, alt17, alt18)
#Export for future use.
saveRDS(alt_all, "data/alt_all.rds")
rm("alt_all")
```


Check missing Altmetric values.
```{r missing-altmetric, eval=FALSE}
alt_all <- readRDS("data/alt_all.rds")
alt_all %>% 
  filter(is.na(altmetric)) %>% 
  select(!c(altmetric, altmetric_3m)) -> alt_na #4359
altna_01 <- plyr::adply(alt_na[1:200, ], .margins = 1, .fun = get_altm)
altna_02 <- plyr::adply(alt_na[201:400, ], .margins = 1, .fun = get_altm)
altna_03 <- plyr::adply(alt_na[401:600, ], .margins = 1, .fun = get_altm)
altna_04 <- plyr::adply(alt_na[601:800, ], .margins = 1, .fun = get_altm)
altna_05 <- plyr::adply(alt_na[801:1000, ], .margins = 1, .fun = get_altm)
altna_all <- rbind(altna_01, altna_02, altna_03, altna_04, altna_05)

altna_all %>% 
  filter(!is.na(altmetric)) # 0 all NAs second time as well
saveRDS(altna_all, "data/altna_all.rds")
```


Calculate summaries of articles.
```{r article-summaries}
# bibliometrix data.frame has the following
# AB =  Abstract, DI = doi, SO = journal title, TC = times cited, 
# TI = article title, PY = publication year 
wosDN <- readRDS("data/wosDN.rds")
wosDN %>% 
  filter(PY %in% study_years) %>% 
  group_by(PY) %>% summarise(count_articles = n()) -> article_summary
# start and end values over time
count_years_articles <- length(unique(article_summary$PY))
start_year_articles <- min(article_summary$PY)
end_year_articles <- max(article_summary$PY)

start_count_articles <- article_summary %>% filter(PY==start_year_articles) %>% 
  pull(count_articles)
end_count_articles <- article_summary %>% filter(PY==end_year_articles) %>% 
  pull(count_articles)

```


Temporal trends in article count of vertebrate studies. 
The number of articles published per year in JCR Biodiversity Conservation journals more than doubled from `r start_count_articles` to `r end_count_articles` over  `r count_years_articles` years.
```{r plot-articles-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in article number across conservaiton journals. Points show published articles per year. Dashed line predictions from GLM (poisson family) and shaded areas 95% CI to aid visual interpretation."}
# use 2011 - 2021. Update with 2022 articles after May 2023.
article_summary %>% 
  ggplot(aes(x=PY, y=count_articles)) + 
  geom_point() + 
  stat_smooth(method = "glm", method.args = list(family = 'poisson'), 
              linetype = "dashed") +
  labs(x="year", 
       y="article count")
```


# Sentiment analysis

```{r test-sentiment, eval=FALSE}
library(sentimentr)
alt_all <- readRDS("data/alt_all.rds")

doi_positive <- "10.1016/j.biocon.2019.02.022"
alt_all %>% 
  filter(DI==doi_positive) %>% pull(AB) -> abstract_positive

mytext <- sentimentr::get_sentences(abstract_positive)
sentiment(mytext)


alt_all[1:6, ] %>% 
  filter(!is.na(AB), !is.na(DI)) %>%
    get_sentences() %$%
    sentiment_by(AB, list(DI))

#171298 sentances
alt_all %>% 
  filter(!is.na(AB), !is.na(DI)) %>% 
  select(DI, AB) %>%
    dplyr::mutate(ab_split = get_sentences(AB)) %>% 
  unnest_longer(ab_split) -> abstract_sentances

saveRDS(abstract_sentances, "data/abstract_sentances.rds")
abstract_sentances %$%
    sentiment_by(ab_split) -> abstract_sentances_sentiment
bind_cols(abstract_sentances, abstract_sentances_sentiment) -> ab_sent_senti
saveRDS(ab_sent_senti, "data/ab_sent_senti.rds")

rm("abstract_sentances")
rm("abstract_sentances_sentiment")
rm("ab_sent_senti")

```

