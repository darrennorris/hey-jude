---
title: "01_development"
author: "Darren Norris"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_depth: 3
    fig_caption: yes
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    number_sections: yes
    extra_dependencies: flafter
    highlight: tango
    includes:
      in_header: preamble.txe
always_allow_html: yes
urlcolor: blue
toc-title: Contents
header-includes:
  - \counterwithin{figure}{section}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE, collapse = TRUE,
  comment = "#>" 
  )
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}", collapse = "\n"))
})
```

\newpage{}

# Load and prep data
## Packages
```{r load-packages, warning=FALSE, message=FALSE}
# Data processing and presentation
library(plyr) # plyr before tidyverse
library(tidyverse)
library(stringr)
library(textclean)
library(readxl)
library(gridExtra)
library(magrittr)
# Tweets
library(rtweet) 
library(academictwitteR)
# bibliometric
library(bibliometrix)
library(rAltmetric)
library(metagear)
# Sentiment
library(sentimentr)
library(SentimentAnalysis)
library(syuzhet)
library(coreNLPsetup)
library(stansent)

```

## Journal impact

[Scopus CiteScore](https://www.elsevier.com/solutions/scopus/how-scopus-works/metrics/citescore) and [JCR Journal Impact Factor ("JIF")](https://clarivate.com/webofsciencegroup/solutions/journal-citation-reports/), downloaded on 24 and 23 January 2023 respectively. 
Using 11 years (2011 to 2021), as 2011 was first year for CiteScore, the year when Altmetrics was founded and also follows the definition of conservation threats and actions published in 2008 (Salafsky et. al., 2008 A Standard Lexicon for Biodiversity Conservation: Unified Classifications of Threats and Actions https://doi.org/10.1111/j.1523-1739.2008.00937.x) and Balmford 2009 for threats 10.1111/j.1523-1739.2009.01196.x  . 
The companies classify journals differently and the folder [data](https://github.com/darrennorris/hey-jude/tree/main/data) has JCR impact of  Biodiversity Conservation category journals (JIF https://github.com/darrennorris/hey-jude/tree/main/data/clarivate_JCR) and matching CiteScore (CiteScore: https://github.com/darrennorris/hey-jude/tree/main/data/scopus_citescore). To match, CiteScore comes from a combination of journals in "Nature and Landscape Conservation", "Ecology, Evolution, Behavior and Systematics" and  the following 12:
African Natural History, Proceedings Of The Linnean Society Of New South Wales, Caribbean Journal Of Science, Urban Ecosystems, Natural History, Revista Chilena De Historia Natural, Polar Biology, Pachyderm, Global Change Biology, Bulletin Of The American Museum Of Natural History, American Museum Novitates, Journal Of Applied Ecology. 


Code below loads and joins CiteScore to JIF. 
```{r load-journal-impact}
jcr_11a21 <-read_excel("data/clarivate_JCR/JCR2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(Journal_name = if_else(Journal_name =="Eco mont-Journal on Protected Mountain Areas Research", "Eco.mont", 
          Journal_name)) %>%
  mutate(name_join = str_to_upper(str_replace_all(Journal_name, "[:punct:]", "")))
cs_NLC_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>% 
  mutate(SourceTitle = if_else(SourceTitle=="Natureza a Conservacao", "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))
# conservation and ecology
cs_NLCECO_11a21 <-read_excel("data/scopus_citescore/citescore_NLC_ECO_2011a2021.xlsx", 
           na = c("", "NA", "N/A")) %>%
  #drop structural NAs
  filter(!is.na(CiteScore)) %>% 
    mutate(SourceTitle = if_else(SourceTitle %in% c("Natureza a Conservacao"), 
                                 "Natureza & Conservacao", SourceTitle)) %>%
  mutate(name_join = str_to_upper(str_replace_all(SourceTitle, "[:punct:]", "")))

jcr_11a21 %>% left_join(cs_NLCECO_11a21, 
                        by = c("ayear"="ayear", 
                               "name_join" = "name_join")) -> journals_11a21
# 12 journals. Differences due to differences in journals and coverage years 
# between databases used to calculate JCR JIF and Scopus CiteScore.
journals_11a21 %>% 
  group_by(Journal_name, name_join) %>% summarise(count_na = sum(is.na(CiteScore))) %>% 
    filter(count_na >0) %>%
  arrange(desc(count_na)) %>% data.frame


```

Calculate descriptive summaries.
```{r journal-impact-summaries, message=FALSE, warning=FALSE}
study_years <- c(2011:2021)
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
  filter(!is.na(value)) %>%
  group_by(ayear, indicator) %>% 
  summarise(journal_count = length(unique(name_join)),
            journal_impact = median(value),
            lq = quantile(value, probs=0.025), 
            uq = quantile(value, probs=0.975)) %>% 
    ungroup() -> journals_11a21_sum
# start and end values over time
count_years <- length(unique(journals_11a21_sum$ayear))
start_year <- min(journals_11a21_sum$ayear)
end_year <- max(journals_11a21_sum$ayear)
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_impact) -> start_JIF
journals_11a21_sum %>% filter(ayear==start_year, indicator=="JIF") %>% 
  pull(journal_count) -> start_count
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_impact) -> end_JIF
journals_11a21_sum %>% filter(ayear==end_year, indicator=="JIF") %>% 
  pull(journal_count) -> end_count

```

Temporal trends in journals. The number of JCR Biodiversity Conservation journals increased from `r start_count` to `r end_count` over  `r count_years` years.

Plot to check patterns in journal impact.
```{r plot-journals-year, out.width="70%", out.height="70%", fig.cap= "Trends in indicators of impacts across conservaiton journals."}
journals_11a21 %>%  
  mutate(ayear = as.character(ayear)) %>% 
  select(ayear, name_join, JIF, CiteScore) %>%
  pivot_longer(cols = c(JIF, CiteScore), names_to = "indicator") %>% 
    filter(!is.na(value)) %>%
  ggplot(aes(x=ayear, y=value)) + 
  geom_point() + 
  geom_boxplot() +
  facet_wrap(~indicator, nrow = 2, scales = "free_y")
```


Plot to check. Median impact and number of journals per year.
```{r plot-journals-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in journal number and indicators of impact across conservaiton journals. Points are median values with verticle lines showing 95% interval of value ranges (0.025 - 0.975 quantile range)."}
journals_11a21_sum %>%
  # use group = 1 so lines go through year which is a factor
  ggplot(aes(x=ayear, y=journal_impact, group=1)) + 
  geom_line(colour="blue", linewidth=1) +
  geom_errorbar(aes(ymin=lq, ymax=uq), width=.1) +
  geom_point(aes(size=journal_count)) + 
  scale_size_continuous("journal\ncount") +
  facet_wrap(~indicator, nrow = 2, scales = "free_y") + 
  labs(x="year", 
       y="impact indicator value")
```

## Article impact

### Literature search checking

Load bibliographic data from WOS core collection.
```{r load-search, eval=FALSE}
# 1) helper functions
# file names
source("R/get_files.R")
# load files
source("R/load_bib.R")
# hack bibliometrix::mergeDbSources to work with list object
source("R/mergeDbSourcesDN.R")

# 2) import and create bibliografic data.frame
infolder <- "data/wos_20230130/"
df_files_wos <- get_files(folder_name = infolder)
lwos <- plyr::alply(df_files_wos, .margins = 1, .fun = load_bib)
# 16795 ( 1 duplicate removed)
wosDN <- mergeDbSourcesDN(lwos, remove.duplicated=TRUE)
saveRDS(wosDN, "data/wosDN.rds")
rm("lwos")
rm("wosDN")

```


### Screening

Screening showed that 24% (48/200) of articles did not meet inclusion criteria (not vertebrates e.g. MAXENT, plants/invertebrates, metaanalysis, review, laboratory).
Screening 100 takes approximately 25 minutes. Screening 16000 would take approximately 67 
hours.
```{r screen-search, eval=FALSE}
wosDN <- readRDS("data/wosDN.rds")
wosDN  %>% 
  filter(!is.na(AB), !is.na(TI)) %>% 
  slice_sample(n=200) -> screen_wos 
screen_wos  %>% 
  #to help use with metagear
  mutate(STUDY_ID = row_number()) -> screen_meta    

#Metagear. Prep to screen to retain only relevant studies
screen_meta %>% mutate(AUTHORS = AU, YEAR = PY, TITLE = TI, 
                    JOURNAL = SO, VOLUME = VL, LPAGES = PP, UPAGES = PP, 
                    DOI = DI, ABSTRACT = AB) %>% 
  select(STUDY_ID, AUTHORS, YEAR, TITLE, JOURNAL, VOLUME, LPAGES, 
         UPAGES, DOI, ABSTRACT) -> screen_metagear

screen_meta_ini <- effort_initialize(screen_metagear, study_ID = FALSE)
theTeam <- c("Darren", "noone")
theRefs_unscreened <- effort_distribute(screen_meta_ini, 
                                        reviewers = theTeam, 
                                        initialize = TRUE,
                                        effort = c(50, 50), 
                                        save_split = TRUE)

abstract_screener("effort_noone1.csv", aReviewer = "noone")

```


### Altimetric

Add altmetrics. To complete.
```{r add-altmetrics, eval=FALSE}
# Politely import altmetrics. "rAltmetrics" retired. "dimensionsR" active.
# 1) helper functions
source("R/altmetrics_updated.R")
source("R/safe_altmetrics.R")
source("R/get_altm.R")

# 2) get altmetrics
wosDN <- readRDS("data/wosDN.rds")

# split to avoid API and internet connection issues
alt01 <- plyr::adply(wosDN[1:500, ], .margins = 1, .fun = get_altm)
alt02 <- plyr::adply(wosDN[501:1000, ], .margins = 1, .fun = get_altm)
alt03 <- plyr::adply(wosDN[1001:2000, ], .margins = 1, .fun = get_altm)
alt04 <- plyr::adply(wosDN[2001:3000, ], .margins = 1, .fun = get_altm)
alt05 <- plyr::adply(wosDN[3001:4000, ], .margins = 1, .fun = get_altm)
alt06 <- plyr::adply(wosDN[4001:5000, ], .margins = 1, .fun = get_altm)
alt07 <- plyr::adply(wosDN[5001:6000, ], .margins = 1, .fun = get_altm)
alt08 <- plyr::adply(wosDN[6001:7000, ], .margins = 1, .fun = get_altm)
alt09 <- plyr::adply(wosDN[7001:8000, ], .margins = 1, .fun = get_altm)
alt10 <- plyr::adply(wosDN[8001:9000, ], .margins = 1, .fun = get_altm)
alt11 <- plyr::adply(wosDN[9001:10000, ], .margins = 1, .fun = get_altm)
alt12 <- plyr::adply(wosDN[10001:11000, ], .margins = 1, .fun = get_altm)
alt13 <- plyr::adply(wosDN[11001:12000, ], .margins = 1, .fun = get_altm)
alt14 <- plyr::adply(wosDN[12001:13000, ], .margins = 1, .fun = get_altm)
alt15 <- plyr::adply(wosDN[13001:14000, ], .margins = 1, .fun = get_altm)
alt16 <- plyr::adply(wosDN[14001:15000, ], .margins = 1, .fun = get_altm)
alt17 <- plyr::adply(wosDN[15001:16000, ], .margins = 1, .fun = get_altm)
alt18 <- plyr::adply(wosDN[16001:16795, ], .margins = 1, .fun = get_altm)
# Results for all 16795
alt_all <- rbind(alt01, alt02, alt03, alt04, alt05, alt06, alt07, alt08, alt09, alt10, 
             alt11, alt12, alt13, alt14, alt15, alt16, alt17, alt18)
#Export for future use.
saveRDS(alt_all, "data/alt_all.rds")
rm("alt_all")
```


Check missing Altmetric values.
```{r missing-altmetric, eval=FALSE}
alt_all <- readRDS("data/alt_all.rds")
alt_all %>% 
  filter(is.na(altmetric)) %>% 
  select(!c(altmetric, altmetric_3m)) -> alt_na #4359
altna_01 <- plyr::adply(alt_na[1:200, ], .margins = 1, .fun = get_altm)
altna_02 <- plyr::adply(alt_na[201:400, ], .margins = 1, .fun = get_altm)
altna_03 <- plyr::adply(alt_na[401:600, ], .margins = 1, .fun = get_altm)
altna_04 <- plyr::adply(alt_na[601:800, ], .margins = 1, .fun = get_altm)
altna_05 <- plyr::adply(alt_na[801:1000, ], .margins = 1, .fun = get_altm)
altna_all <- rbind(altna_01, altna_02, altna_03, altna_04, altna_05)

altna_all %>% 
  filter(!is.na(altmetric)) # 0 all NAs second time as well
saveRDS(altna_all, "data/altna_all.rds")
```

# Literature search results

Calculate summaries of articles.
```{r article-summaries}
# bibliometrix data.frame has the following
# AB =  Abstract, DI = doi, SO = journal title, TC = times cited, 
# TI = article title, PY = publication year 
wosDN <- readRDS("data/wosDN.rds")
wosDN %>% 
  filter(PY %in% study_years) %>% 
  group_by(PY) %>% summarise(count_articles = n()) -> article_summary
# start and end values over time
count_years_articles <- length(unique(article_summary$PY))
start_year_articles <- min(article_summary$PY)
end_year_articles <- max(article_summary$PY)

start_count_articles <- article_summary %>% filter(PY==start_year_articles) %>% 
  pull(count_articles)
end_count_articles <- article_summary %>% filter(PY==end_year_articles) %>% 
  pull(count_articles)

```


Temporal trends in article count of vertebrate studies. 
The number of articles published per year in JCR Biodiversity Conservation journals more than doubled from `r start_count_articles` to `r end_count_articles` over  `r count_years_articles` years.
```{r plot-articles-year-count, message=FALSE, warning=FALSE,out.width="70%", out.height="70%", fig.cap= "Trends in article number across conservaiton journals. Points show published articles per year. Dashed line predictions from GLM (poisson family) and shaded areas 95% CI to aid visual interpretation."}
# use 2011 - 2021. Update with 2022 articles after May 2023.
article_summary %>% 
  ggplot(aes(x=PY, y=count_articles)) + 
  geom_point() + 
  stat_smooth(method = "glm", method.args = list(family = 'poisson'), 
              linetype = "dashed") +
  labs(x="year", 
       y="article count")
```


# Sentiment analysis

May need to also use custom classifier (e.g. Twitter optimism https://doi.org/10.1098/rsos.190473), machine learning available via [superml](https://github.com/saraswatmks/superml).

Human classified text to help calibrate sentiment scores.

## Twitter
Human classified tweets to help calibrate sentiment scores.
Human annotated classification available for tweets? 
http://dx.doi.org/10.1098/rsos.190473
https://doi.org/10.1371/journal.pone.0155036 (https://www.clarin.si/repository/xmlui/handle/11356/1054)

Get tweets with associated human sentiment.
Test and download Tweets.
```{r twitter, eval=FALSE}

#API key: g6IwJTpYXHGRFj2M9rhfcljE2
#API Key Secret  cvSWp2ccBKFJFJ5K1lUUxnaoJgpupxP91HVtwrI3lojHWV9sXK
#API Access Token 1393632534676787205-3rPq6YwjqA9LD2YYX36VMwKNCuh8Nz
#API Access Token Secret: 0QUqf3168seUaPCr0i3OKUDtIrgwUXD1JrIqiDIZzj8ps

# https://doi.org/10.1007/s13278-016-0327-z
# https://zenodo.org/record/4255764#.Y96g7nbMLIU

# Read tweet ids
# from https://royalsocietypublishing.org/doi/suppl/10.1098/rsos.190473
twitter_sentiment <- readxl::read_excel("data/human_twitter_sentiment.xlsx")
twitter_sentiment %>% pull('TWEET_ID_TEXT') -> myids
# Twitter airline sentiment (with tweet text)
# https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment 


api_key <- "g6IwJTpYXHGRFj2M9rhfcljE2"
api_secret_key <- "cvSWp2ccBKFJFJ5K1lUUxnaoJgpupxP91HVtwrI3lojHWV9sXK"
access_Token <- "1393632534676787205-3rPq6YwjqA9LD2YYX36VMwKNCuh8Nz"
access_TokenSecret <- "0QUqf3168seUaPCr0i3OKUDtIrgwUXD1JrIqiDIZzj8ps"
mybearer <- "AAAAAAAAAAAAAAAAAAAAAGSAlgEAAAAAVf81AnZ7G4uIAa9QI%2FVnQtPn%2FXE%3DRMzghgq1vBEyGo2NXydxWdMleY3DmPBbyJwHMwbhtpf5VyY3wb"
# below works when RStudio has administrator and bing is signed into twitter
rtweet::auth_setup_default()
tweets <- search_tweets("weather", n=2)
 statuses <- c(
    "567053242429734913",
    "266031293945503744",
    "440322224407314432", 
    "14946300000000000"
  )
tw <- lookup_tweets(myids, retryonratelimit = TRUE)
tw %>% left_join(twitter_sentiment, by=c("id_str"="TWEET_ID_TEXT")) %>%
  group_by(SENTIMENT) %>% summarise(acount=length(unique(id_str)))
# negative	13			
# neutral	138			
# positive	105	
saveRDS(tw, "data/twitter_optimism.RDS")

```

sentiment_trainingandtestdata Data file format has 6 fields:
0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)
1 - the id of the tweet (2087)
2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)
3 - the query (lyx). If there is no query, then this value is NO_QUERY.
4 - the user that tweeted (robotickilldozr)
5 - the text of the tweet (Lyx is cool) . Go et al. at 2009, the Sentiment140 Tweet data from 2009
Twitter sentiment. To do .....
```{r}

```

## Other sentiment datasets.

FinancialPhraseBank-v1.0  This dataset contains the sentiments for financial news headlines from the perspective of a retail investor. Malo, P., Sinha, A., Takala, P., Korhonen, P. and Wallenius, J. (2013): “Good debt or bad debt: Detecting semantic orientations in economic texts.” Journal of the American Society for Information Science and Technology. 

sentiment_labelled_sentences. Contains sentences labelled with positive or negative sentiment, extracted from reviews of products, movies, and restaurants. From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015

```{r get-txt}
# 2264 phrases with 100% agreement
txt_01 <- "data/sentiment_FinancialPhraseBank-v1.0/Sentences_AllAgree.txt"
Sentiment_finance <- readr::read_delim(txt_01, delim = "@", escape_double = FALSE, 
                                       col_names = c("sentence", "sentiment"), 
                                       trim_ws = TRUE) %>% mutate(source = "finance")
Sentiment_finance %>% 
  group_by(sentiment) %>% summarise(acount = n())
#negative	303			
#neutral	1391			
#positive	570	

txt_02 <- "data/sentiment_labelled_sentences/amazon_cells_labelled.txt"
txt_03 <- "data/sentiment_labelled_sentences/imdb_labelled.txt"
txt_04 <- "data/sentiment_labelled_sentences/yelp_labelled.txt"
sentiment_review <- bind_rows (read_delim(txt_02, delim = "\t", escape_double = FALSE, 
                               col_names =c("sentence","sentiment"), trim_ws = TRUE) %>% 
                                 mutate(source = "amazon"), 
                               read_delim(txt_03, delim = "\t", escape_double = FALSE, 
                               col_names =c("sentence","sentiment"), trim_ws = TRUE) %>% 
                                 mutate(source = "imdb"), 
                               read_delim(txt_04, delim = "\t", escape_double = FALSE, 
                               col_names =c("sentence","sentiment"), trim_ws = TRUE) %>% 
                                 mutate(source = "yelp") 
)
  
# join
bind_rows(Sentiment_finance, 
          sentiment_review %>% 
            mutate(sentiment = if_else(sentiment=="0", "negative", "positive"))) -> sentiment_phrases

sentiment_phrases %>% 
  group_by(sentiment) %>% summarise(acount=n())
# negative	1395			
# neutral	1391			
# positive	1701

```



```{r text-sentiment, eval=FALSE}
sentiment_phrases %>% 
  mutate(sent_01 = replace_emoji(sentence)) %>% 
  mutate(sent_02 = replace_html(sent_01)) %>%
    dplyr::mutate(phrase_split = get_sentences(sent_02)) %>% 
  unnest_longer(phrase_split) -> phrase_split

phrase_sentances %$%
    sentiment_by(phrase_split) -> phrase_sentances_sentiment

sentiment_phrases %>% left_join(
bind_cols(phrase_sentances %>% select(sentence, phrase_split), 
          phrase_sentances_sentiment) %>% 
  group_by(sentence) %>% 
  summarise(rev_word_count = sum(word_count), 
            rev_sentance_count = n(), 
            rev_sentiment_min = round(min(ave_sentiment),4), 
            rev_sentiment_max = round(max(ave_sentiment),4), 
            rev_sentiment_med = round(median(ave_sentiment),3),
            rev_sentiment_sd = round(sd(ave_sentiment),3)) 
) -> sentiment_phrases_reviews

saveRDS(sentiment_phrases_reviews, "data/sentiment_phrases_reviews.RDS")

```

Plot to check
```{r plot-human, fig.cap="Sentiment scores of human annotated text . Values across four sources 2264 investor sentiments for financial news headlines (finance), and 2223 positive or negative sentiment, extracted from reviews of products (Amazon), films (IMDB), and restaurants (Yelp). "}


sentiment_phrases_reviews <- readRDS("data/sentiment_phrases_reviews.RDS")
# # 25th and 75th percentiles
sentiment_phrases_reviews %>% 
  filter(source=="finance", sentiment=="neutral") %>% 
  pull(rev_sentiment_med) %>% Hmisc::smean.cl.boot(conf.int=.95) -> bootci
lcl <- bootci[2]
ucl <- bootci[3]

#
sentiment_phrases_reviews %>% 
  ggplot(aes(x=sentiment, y = rev_sentiment_med)) +
  #geom_point(aes(fill = factor(source))) + 
  geom_violin(aes(fill = factor(source)), draw_quantiles=0.5) + 
  #geom_hline(yintercept = lcl, linetype = "dashed") + 
  #geom_hline(yintercept = ucl, linetype = "dashed") +
  scale_fill_discrete("source") + 
  labs(x="human annotated sentiment", 
       y="sentiment score")

```


## Text sentiment

Look at scores for simple phrases. Use example by Dr Joanna (Annie) Swafford (https://annieswafford.wordpress.com/2015/03/02/syuzhet/)

```{r simple-sentiment, fig.width=7, fig.height=8}

# added a few sentences to Annie Swafford example
ase <- c( 
  "What shall I do today?",
  "Take a sad song and make it better.", 
    "I am very pleased with it so far.",
    "I haven't been sad in a long time.",
    "I am extremely happy today.",
    "It's a good day.",
    "But suddenly I'm only a little bit happy.",
    "Then I'm not happy at all.",
    "In fact, I am now the least happy person on the planet.",
    "There is no happiness left in me.",
    "Wait, it's returned!",
    "I don't feel so bad after all!",
  "I think to myself what a wonderful world."
)
mysentiments <- c("neutral","positive", "positive", "neutral", "positive", "positive", "positive", "negative", "negative", "negative", "neutral", "neutral", "positive")
myscores <- c(0, 0.75, 1, 0, 1, 1, 0.75, -0.5, -1, -1, 0, 0, 1) 
myaid = paste("sent_", 
                     c("01", "02", "03", "04", "05", "06", 
                       "07", "08", "09", "10", "11", "12", "13"), sep="")
dftest <- data.frame(sentence = ase, sentiment = mysentiments, score = myscores, 
                     aid = myaid, sent_order = 1:13)
s_rinker <- sentiment_by(dftest$sentence, 
                         polarity_dt = lexicon::hash_sentiment_jockers_rinker, 
                         question.weight = 0) %>% 
  rename("ave_sent_rinker"="ave_sentiment")
sort(unique(s_rinker$ave_sent_rinker))
# Liu & HU (2004) 
s_hu <- sentiment_by(dftest$sentence, 
                     polarity_dt = lexicon::hash_sentiment_huliu, 
                     question.weight = 0) %>% 
  rename("ave_sent_huliu"="ave_sentiment")
sort(unique(s_hu$ave_sent_huliu))
s_jockers <- sentiment_by(dftest$sentence, 
                     polarity_dt = lexicon::hash_sentiment_jockers, 
                     question.weight = 0) %>% 
  rename("ave_sent_jockers"="ave_sentiment")
sort(unique(s_jockers$ave_sent_jockers))
# SentimentAnalysis  
# GI = Dictionary with opinionated words from the Harvard-IV dictionary as used in the General Inquirer software
# LM = Loughran-McDonald Financial dictionary (Loughran and McDonald 2011)
# QDAP = dictionary from the package qdapDictionaries
sa <- SentimentAnalysis::analyzeSentiment(dftest$sentence) 

# Stanford coreNLP
out1 <- sentiment_stanford(dftest$sentence) %>% 
  rename("ave_sent_stanford"="sentiment")
#syuzhet
sent_syuzhet <- get_sentiment(dftest$sentence, method="syuzhet")
sent_bing <- get_sentiment(dftest$sentence, method="bing")
sent_nrc <- get_sentiment(dftest$sentence, method="nrc")
data.frame(score = sent_syuzhet, sent=dftest$sentiment)
dfsyuzhet <- data.frame(syuzhet_syuzhet=sent_syuzhet, syuzhet_bing = sent_bing, 
                        syuzhet_nrc=sent_nrc)
class(dfsyuzhet[, 'syuzhet_syuzhet'])
dfsyuzhet %>% select(syuzhet_syuzhet)
#
bind_cols(dftest, s_hu[, c('word_count', 'ave_sent_huliu')], 
          s_rinker[, 'ave_sent_rinker'], s_jockers[, 'ave_sent_jockers'],
          out1[, 'ave_sent_stanford'], dfsyuzhet,
          sa %>% select(WordCount, SentimentGI, SentimentLM, SentimentQDAP) 
) %>% 
  select(aid, sentence, sentiment, word_count, ave_sent_huliu, ave_sent_rinker, ave_sent_jockers,
         syuzhet_syuzhet, syuzhet_bing, syuzhet_nrc, ave_sent_stanford, SentimentGI, SentimentLM, SentimentQDAP) %>% 
  pivot_longer(cols=c(ave_sent_huliu, ave_sent_rinker, ave_sent_jockers, ave_sent_stanford, syuzhet_syuzhet,syuzhet_bing,syuzhet_nrc, SentimentGI, SentimentLM, SentimentQDAP)) %>% 
  ggplot(aes(x=factor(sentiment), y = value, fill = factor(name))) + 
    geom_violin(draw_quantiles=0.5) + 
  geom_point(position=position_jitterdodge()) +
  geom_hline(yintercept = 0) +
  scale_fill_discrete("lexicon") + 
  labs(x="human annotated sentiment", 
       y="sentiment score") + 
  coord_flip()
           
```
Ensemble approach with four "best" dictionaries.

```{r sentiment-ensemble}

bind_cols(dftest, s_hu[, c('word_count', 'ave_sent_huliu')], 
          s_rinker[, 'ave_sent_rinker'], s_jockers[, 'ave_sent_jockers'],
          out1[, 'ave_sent_stanford']) %>%
  select(aid, sentence, sentiment, word_count, 
         ave_sent_huliu, 
         ave_sent_rinker, 
         ave_sent_jockers,
         ave_sent_stanford) %>% 
  pivot_longer(cols=c(ave_sent_rinker, ave_sent_huliu, ave_sent_jockers, ave_sent_stanford)) %>% 
  #group_by(aid, sentiment, sentence) %>% summarise(med_sent = median(value), 
   #                                           min_sent = min(value), 
   #                                           max_sent = max(value)) %>%
  ggplot(aes(x=factor(sentiment), y = value)) + 
    geom_violin(aes(fill = factor(name)), draw_quantiles = 0.5) + 
  #geom_point(size = 2, aes(col = factor(aid), shape=factor(name)), 
  #           position=position_dodge(width=0.3)) +
  #geom_errorbar(aes(ymin = min_sent, ymax = max_sent, 
  #                  col = factor(aid)), 
   #             position=position_dodge(width=0.2))
  #scale_fill_discrete("lexicon") + 
  labs(x="human annotated sentiment", 
       y="sentiment score")

```

Use 4 best sentiment lexicons to model sentiment directions. Where confidence interval overlaps zero then is neutral (?). Sentence nine is most problematic, with only one lexicon (Stanford) scoring this negative sentence correctly (sentence: "In fact, I am now the least happy person on the planet."). But Stanford also scores positive sentences as negative in one case.
```{r sentiment-direction-ensemble, fig.width=7, fig.height=6, fig.cap="Comparison of human and automated sentiment scores. Annotaded scores by Darren (A) and four most consistent lexicon diciionaires (B). Coloured points and lines indicate different lexicon scores (points are dodged horizontally to avoid overlapping). Dashed line is prediciton from GAM model with grey shading showing 95% CI."}

ggplot(dftest, aes(x=sent_order, y=score)) + 
  geom_hline(yintercept=0) +
  geom_point() + 
  geom_line() + 
  scale_x_continuous(breaks = c(1,3,5,7,9,11,13)) + 
  labs(title = "(A) Human", 
  x="sentence order", 
       y="human annotated sentiment score") -> fig_sent_h

bind_cols(dftest, s_hu[, c('word_count', 'ave_sent_huliu')], 
          s_rinker[, 'ave_sent_rinker'], s_jockers[, 'ave_sent_jockers'],
          out1[, 'ave_sent_stanford']) %>% 
  select(aid, sent_order, sentence, score, sentiment, word_count, 
         ave_sent_huliu, 
         ave_sent_rinker, 
         ave_sent_jockers,
         ave_sent_stanford) %>% 
  pivot_longer(cols=c(ave_sent_rinker, ave_sent_huliu, ave_sent_jockers, ave_sent_stanford)) %>% 
  ggplot(aes(x = sent_order, y = value)) + 
  geom_hline(yintercept=0) +
  geom_jitter(aes(colour = name)) + 
  geom_line(aes(color = as.factor(name))) +
  stat_smooth(method = "gam",formula = y ~ s(x, k = 13),
              linetype="dashed") + 
  scale_x_continuous(breaks = c(1,3,5,7,9,11,13)) +
  labs(title="(B) Sentiment lexicon", 
       x="sentence order", 
       y="sentiment score") + 
  theme(legend.position = c(0.7, 0.85)) + 
  guides(color = guide_legend(nrow = 2)) -> fig_sent_lex

grid.arrange(fig_sent_h, fig_sent_lex, nrow=2)
```




## Abstract sentiment.

Repeat ensemble approach for Abstracts. Test with one optimistic, one neutral and one negative.
```{r abstract-test-examples}

# Test on an optimistic example
ab_positive <- data.frame(doi= "10.1016/j.biocon.2019.02.022", 
                          title = "Prospects for freshwater turtle population recovery are catalyzed by pan-Amazonian community-based management", 
                          sentence = c("Sustainable use as a mechanism for the conservation and recovery of exploited wildlife populations remains intensely debated, including for freshwater turtles, a diverse and imperiled group of aquatic reptiles that are an important food source for many residents of tropical regions.", 
                                       "Here we evaluated the geographical extent of recovery options for a heavily exploited tropical freshwater turtle fauna across 8.86 M km2 of South American river catchments under scenarios of Business-as-Usual (BAU), Protection (Pr) and Community-Based-Management (CBM).", 
                                       "For the widespread indicator species, Podocnemis unifilis, demographic analysis showed that populations subject to moderate levels of female harvest (≤10%) can recover over broad areas if concurrent headstarting of hatchlings is practiced more widely.", 
                                       "With regional strengthening of the protected area network unlikely, CBM developed with harvest frameworks derived from demographic rates appropriate to tropical species could catalyze a rapid continental scale recovery of Amazonian freshwater turtles within a few decades."), 
                          sentiment = c("neutral", "neutral", "positive", "positive"), 
                          score = c(0,0,0.5,0.75), 
                          aid = c("01","02","03","04"), 
                          sent_order = 1:4 
)
                          
ab_negative <- data.frame(doi = "10.1126/science.aay5733", title = "Tropical snake diversity collapses after widespread amphibian loss", 
                          sentence = c(
                            "Biodiversity is declining at unprecedented rates worldwide.",
                          "Yet cascading effects of biodiversity loss on other taxa are largely unknown because baseline data are often unavailable.", 
                          "We document the collapse of a Neotropical snake community after the invasive fungal pathogen Batrachochytrium dendrobatidis caused a chytridiomycosis epizootic leading to the catastrophic loss of amphibians, a food source for snakes.", 
                          "After mass mortality of amphibians, the snake community contained fewer species and was more homogeneous across the study site, with several species in poorer body condition, despite no other systematic changes in the environment.", 
                          "The demise of the snake community after amphibian loss demonstrates the repercussive and often unnoticed consequences of the biodiversity crisis and calls attention to the invisible declines of rare and data-deficient species."), 
                          sentiment = c("negative", "negative", "negative", "negative", "negative"), 
                          score = c(-0.5, -0.25, -0.75, -0.75, -0.25),
                          aid = c("01","02","03","04", "05"), sent_order = 1:5)                          



```


```{r test-sentiment, eval=FALSE}
alt_all <- readRDS("data/alt_all.rds")

# Abstracts
alt_all[1:6, ] %>% 
  filter(!is.na(AB), !is.na(DI)) %>%
    get_sentences() %$%
    sentiment_by(AB, list(DI))

#171298 sentances
alt_all %>% 
  filter(!is.na(AB), !is.na(DI)) %>% 
  select(DI, AB) %>%
    dplyr::mutate(ab_split = get_sentences(AB)) %>% 
  unnest_longer(ab_split) -> abstract_sentances

saveRDS(abstract_sentances, "data/abstract_sentances.rds")
abstract_sentances %$%
    sentiment_by(ab_split) -> abstract_sentances_sentiment
bind_cols(abstract_sentances, abstract_sentances_sentiment) -> ab_sent_senti
ab_sent_senti %>% 
  group_by(DI, AB) %>% 
  summarise(ab_word_count = sum(word_count), 
            ab_sentance_count = n(), 
            ab_sentiment_min = round(min(ave_sentiment),4), 
            ab_sentiment_max = round(max(ave_sentiment),4), 
            ab_sentiment_med = round(median(ave_sentiment),3),
            ab_sentiment_sd = round(sd(ave_sentiment),3)) -> ab_sent_senti
saveRDS(ab_sent_senti, "data/ab_sent_senti.rds")

# Titles
#recommended process flow, but uncombine adds duplicate rows dont use.
#alt_all[1:6, ] %>%
#    get_sentences() %$%
#    sentiment_by(TI, list(AU, PY, DI)) -> title_sent
#uncombine(title_sent)

alt_all %>% 
  filter(!is.na(TI), !is.na(DI)) %>% 
  select(DI, TI) %>%
    dplyr::mutate(title_split = get_sentences(TI)) %>% 
  unnest_longer(title_split) -> title_sentances

title_sentances %$%
    sentiment_by(title_split) -> title_sentances_sentiment

bind_cols(title_sentances, title_sentances_sentiment) -> title_sent_senti
title_sent_senti %>% 
  group_by(DI, TI) %>% 
  summarise(ti_word_count = sum(word_count), 
            ti_sentance_count = n(), 
            ti_sentiment_min = round(min(ave_sentiment),4), 
            ti_sentiment_max = round(max(ave_sentiment),4), 
            ti_sentiment_med = round(median(ave_sentiment),3),
            ti_sentiment_sd = round(sd(ave_sentiment),3)) -> ti_sent_senti
saveRDS(title_sent_senti, "data/title_sent_senti.rds")

# join sentiment to articles
alt_all %>% 
  left_join(ab_sent_senti) %>% 
  left_join(ti_sent_senti) -> all_alti_senti

# Export for future use
saveRDS(all_alti_senti, "data/all_alti_senti.RDS")
write.csv(all_alti_senti, "data/all_alti_senti.csv")
rm("abstract_sentances")
rm("abstract_sentances_sentiment")
rm("ab_sent_senti")
rm("title_sentances")
rm("title_sentances_sentiment")
rm(ti_sent_senti)
rm(alt_all)
rm(alt_na)

```


Summaries of sentiment.
```{r abstract-sentiment-summary}
# check for differences in counts of journal names. Same journal changes name etc?
# Need to standardize journal names in WOS search results.
all_alti_senti <- readRDS("data/all_alti_senti.RDS")
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(SO) %>% 
  unique() %>% length() -> journal_count_ab # 81
jcr_11a21 %>% 
  filter(ayear %in% study_years) %>% pull(Journal_name) %>% 
  unique() %>% length() -> journal_count_jcr # 73
jcr_11a21 %>% 
  filter(ayear %in% study_years) %>% pull(ISSN) %>% 
  unique() %>% length() -> journal_count_issn # 69

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(DI) %>% 
  unique() %>% length() #14330

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), PY %in% study_years) %>% pull(DI) %>% 
  unique() %>% length() -> article_count_doi#14330

all_alti_senti %>%
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric),PY %in% study_years) %>% 
  pull(DI) %>% 
  unique() %>% length() # 10395
all_alti_senti %>%
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), 
         !is.na(TC),PY %in% study_years) %>% 
  pull(DI) %>% 
  unique() %>% length() # 10395
```
Correlation.
```{r sentiment-correlation}
df1a1 <- data.frame(ab_sentiment_med = seq(-2,2), ti_sentiment_med = seq(-2,2))

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>%
  ggplot(aes(x=ab_sentiment_med, y=ti_sentiment_med)) +
  geom_point() + 
  geom_line(data= df1a1, aes(x=ab_sentiment_med, y=ti_sentiment_med)) +
  stat_smooth(method="lm", linetype="dashed") + 
  coord_fixed(xlim=c(-1,1), ylim=c(-1.6, 1.4)) +
  labs(x="Abstract sentiment", y="Title sentiment")

```


Plot to see/explore. Temporal trrends in abstract and title sentiment.
```{r plot-sentiment-year, fig.height=5, fig.width=7}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
    select(PY, altmetric, TC, ab_sentiment_med, ti_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(ab_sentiment_med, ti_sentiment_med)) %>% 
  mutate(name = if_else(name=="ab_sentiment_med", "abstract sentiment", 
                        "title sentiment")) %>%
  ggplot(aes(x=factor(PY), y=value)) + 
  geom_point() + 
  geom_violin(draw_quantiles = 0.5) + 
  coord_flip() + 
  facet_wrap(~name) +
  labs(x="year", y="sentiment")
```

Relationship between article impact and Abstract sentiment.

```{r plot-article-impact-sentiment, fig.height=6, fig.width=5}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
  select(PY, altmetric, TC, ab_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(altmetric, TC)) %>% 
  mutate(name = if_else(name=="TC", "times cited", name)) %>%
  ggplot(aes(x=value, y = ab_sentiment_med)) + 
  geom_point() + 
  geom_smooth(method = "gam")+
  facet_grid(year~name, scales = "free_x") + 
  labs(x="article impact", y="Abstract sentiment")
```


Relationship between article impact and title sentiment.

```{r plot-title-impact-sentiment, fig.height=6, fig.width=5}
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years) %>% 
  select(PY, altmetric, TC, ti_sentiment_med) %>% 
  mutate(year = factor(PY)) %>% 
  pivot_longer(cols = c(altmetric, TC)) %>% 
  mutate(name = if_else(name=="TC", "times cited", name)) %>%
  ggplot(aes(x=value, y = ti_sentiment_med)) + 
  geom_point() + 
  geom_smooth(method = "gam")+
  facet_grid(year~name, scales = "free_x") + 
  labs(x="article impact", y="title sentiment")
```

Trim extreme values (Zuur 2010  https://doi.org/10.1111/j.2041-210X.2009.00001.x)? Do article impact indicators and sentiment values have 
extreme values?

Citations per year and title sentiment.
```{r plot-citations-per-year, fig.width=7, fig.height=12}
# citations per year
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>%
  arrange(cite_per_year) %>% 
  mutate(cite_order = row_number()) %>% 
  ggplot(aes(x=cite_per_year, y=cite_order)) + 
  geom_jitter(width=3, aes(col=ti_sentiment_med), alpha=0.3, size=2) + 
  scale_colour_gradient2("title\nsentiment", 
                         low = "red", mid = "grey80", high = "green") +
  facet_wrap(~PY, scales = "free", ncol = 2) + 
  labs(title = "(A)", y="order of times cited per year", 
       x = "times cited per year") + 
  theme_bw()
```

Citations per year and abstract sentiment.
```{r plot-citations-per-year-abstract, fig.width=7, fig.height=12}
# citations per year
all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>%
  arrange(cite_per_year) %>% 
  mutate(cite_order = row_number()) %>% 
  ggplot(aes(x=cite_per_year, y=cite_order)) + 
  geom_jitter(width=3, aes(col=ab_sentiment_med), alpha=0.3, size=2) + 
  scale_colour_gradient2("abstract\nsentiment", 
                         low = "red", mid = "grey80", high = "green") +
  facet_wrap(~PY, scales = "free", ncol = 2) + 
  labs(title = "(A)", y="order of times cited per year", 
       x = "times cited per year") + 
  theme_bw()
```


Explore data with Cleveland plots.


```{r cleveland-plot-citation, fig.width=8, fig.height=12}
# Okabe-Ito colour blind safe
okabe <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  mutate(cite_per_year = TC/(2022 - PY)) %>% 
#  pull(cite_per_year) %>% summary() 
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  0.000   1.500   3.000   4.351   5.444 158.000 
  arrange(cite_per_year) %>%
  mutate(cite_rank = rank(cite_per_year), 
         cite_order = row_number(),
         flag_sentiment = case_when(ab_sentiment_min<0 & ab_sentiment_med<0 ~ "negative", 
                                    ab_sentiment_min>0 & ab_sentiment_med>0 ~ "positive", 
                                    TRUE ~"neutral") 
         ) %>% 
  ggplot(aes(x=altmetric, y=cite_per_year)) + 
  geom_jitter(aes(colour=flag_sentiment), height=1, alpha=0.4) +
  stat_smooth(aes(colour=flag_sentiment), method = "gam", se=FALSE) +
  scale_colour_manual("abstract\nsentiment", 
                      values = c("#E69F00", "grey70", "#009E73")) + 
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(A)", y="times cited per year", 
       x = "altimetric") + 
  theme_bw() + theme(legend.position="top") + 
  guides(color = guide_legend(nrow = 2)) -> fig_citation


all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  arrange(TC) %>% 
  mutate(ti_order = rank(ti_sentiment_med)) %>% 
  ggplot(aes(x=ab_sentiment_med, y=ti_order)) + 
  geom_point(aes(colour=TC)) + 
  scale_color_viridis_c("times\ncited", trans = "log1p") +
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(B)", x="abstract sentiment", 
       y="rank title sentiment") + theme(legend.position="top") -> fig_sent_cite

all_alti_senti %>% 
  filter(!is.na(AB), !is.na(DI), !is.na(altmetric), PY %in% study_years, 
         !DI=="10.1111/j.1472-4642.2010.00725.x") %>% 
  arrange(altmetric) %>% 
  mutate(ti_order = rank(ti_sentiment_med)) %>% 
  ggplot(aes(x=ab_sentiment_med, y=ti_order)) + 
  geom_point(aes(colour=altmetric)) + 
  scale_color_viridis_c("altmetric", trans = "log1p") +
  facet_wrap(~PY, scales = "free", ncol = 1) + 
  labs(title = "(C)", x="abstract sentiment", 
       y="rank title sentiment") + theme(legend.position="top") -> fig_sent_alt


gridExtra::grid.arrange(fig_citation, fig_sent_cite, fig_sent_alt, nrow=1)

```


Tidy to keep workspace small.
```{r tidy-workspace}
rm(fig_citation)
rm(fig_sent_alt)
rm(fig_sent_cite)
```

