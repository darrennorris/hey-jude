---
title: "01_development"
author: "Darren Norris"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_depth: 3
    fig_caption: yes
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    number_sections: yes
    extra_dependencies: flafter
    highlight: tango
    includes:
      in_header: preamble.txe
always_allow_html: yes
urlcolor: blue
toc-title: Contents
header-includes:
  - \counterwithin{figure}{section}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE, collapse = TRUE,
  comment = "#>" 
  )
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}", collapse = "\n"))
})
```

\newpage{}

## Packages
```{r load-packages, warning=FALSE, message=FALSE}
# Data processing and presentation
library(plyr) # plyr before tidyverse
library(tidyverse)
library(stringr)
library(textclean)
library(readxl)
library(gridExtra)
library(magrittr)
library(rcrossref)

```

## Load CE data
 CE https://www.conservationevidence.com/content/page/111 
 "Finding documented evidence" lists inclusion criteria
- There must have been an intervention that conservationists would do.
- Its effects must have been monitored quantitatively and documented.
Does not include studies that solely report monitoring methods, species ecology, biodiversity surveys, or threats to biodiversity.
```{r load-data}
# Has Conservation Evidence from the following synopses Amphibian, Bat, Bird, Management of captive animals, marine and freshwater mammals, marine fish, primates, reptiles, terrestrial mammals
# 2013 Bird
# 2014 Amphibian
# 2017 Primate
# 2018 Management of Captive Animals
# 2020 Terrestrial Mammal
# 2021 Bat, Reptile, Marine and Freshwater Mammal, Marine Fish
# Few Conservation Biology and Biodiversity and Conservation 
# 7874 - doi incorrect. Use manually adjusted dois
# 10316 - doi incorrect duplicate of 10478
# 8599 doi duplicate of 8598
# 10475 url duplicate of 10237

cedat <- read_excel('data/studydat_fordarrenn_24_02_2023DN.xlsx')
cedat %>% 
  # with 2011 lose 97 bird studies
  #filter(publication.year>=2011) %>%
  group_by(synopsis.name) %>% 
  summarise(study_count = length(unique(study.id)))

cedat %>% 
  # with 2011 lose 97 bird studies
  filter(synopsis.name=="Bird Conservation") %>%
  group_by(journal.name) %>% 
  summarise(study_count = length(unique(study.id))) %>% 
  arrange(desc(study_count))

cedat %>% 
  filter(publication.year>=2011) %>%
  # 1094 studies
  group_by(study.id, publication.year, publication.title, 
           journal.name,doi, url) %>% 
  summarise(intervention_count = n()) %>% 
  ungroup() -> cedat_studies
cedat_studies %>% nrow() #1094
# 35 not journals
cedat_studies %>% 
  filter(is.na(journal.name)) %>% nrow()
# 819 dois are NA
cedat_studies %>% 
  filter(is.na(doi)) %>% nrow()
# 275 dois not NA
cedat_studies %>% 
  filter(!is.na(doi)) %>% nrow()

cedat_studies %>% 
  filter(!is.na(journal.name)) %>% 
  group_by(journal.name) %>% summarise(article_count = n()) %>% 
  arrange(desc(article_count))

```

### Add birds
CE searched 3 March 2023. Filter birds and years 2011 - 2022 = 53 studies.
https://www.conservationevidence.com/data/studies?pp=100&broad_id%5B%5D=2&country%5B%5D=&result_type=references&sort=publication_year#searchcontainer

```{r}
library(synthesisr)
cebird <- read_refs(
  filename = "data/2023-03-03.ris",
  return_df = TRUE)

```


## Get dois from CE data.
```{r get-dois}
# Create new doi column to join with bibliometrics
# clean out prefixes
doi_prefix <- c("http://dx.doi.org/DOI:", "http://dx.doi.org/doi:", 
"http://dx.doi.org/", "https://dx.doi.org/DOI:", "https://dx.doi.org/doi:", 
"https://dx.doi.org/", 
"DOI:", "http://doi.org/", "https://doi.org/")
doi_prefix_string <- paste(doi_prefix,collapse="")

journal_doi_prefix <- c( "http://www.asmjournals.org/doi/abs/",
"http://link.springer.com/article/",  
"https://link.springer.com/chapter/", 
"https://link.springer.com/content/pdf/",
"http://www.bioone.org/doi/abs/", "http://www.karger.com/DOI/", 
"http://www.tandfonline.com/doi/abs/", 
"https://besjournals.onlinelibrary.wiley.com/doi/epdf/",
"https://besjournals.onlinelibrary.wiley.com/doi/abs/", 
"https://journals.plos.org/plosone/article/file?id=", 
"https://journals.plos.org/plosone/article?id=", 
"http://journals.sagepub.com/doi/abs/",
"https://link.springer.com/article/", 
"https://www.frontiersin.org/articles/",
"https://onlinelibrary.wiley.com/doi/epdf/",
"https://onlinelibrary.wiley.com/doi/pdf/",
"https://onlinelibrary.wiley.com/doi/abs/", 
"https://onlinelibrary.wiley.com/doi/full/", 
"https://onlinelibrary.wiley.com/doi/",
"http://onlinelibrary.wiley.com/doi/", 
"https://royalsocietypublishing.org/doi/pdf/",
"https://wildlife.onlinelibrary.wiley.com/doi/abs/", 
"https://wildlife.onlinelibrary.wiley.com/doi/pdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/epdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/pdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997426723&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951076741&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959282517&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940942773&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949952613&doi="
)

cedat_studies %>% 
  mutate(doi = str_trim(doi), 
         url = str_trim(url)) %>%
  mutate(doi_ce = str_replace(doi, doi_prefix[1], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[2], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[3], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[4], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[5], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[6], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[7], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[8], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[9], "")) %>% 
  mutate(doi_ce = if_else(study.id ==7943 ,"10.1016/j.jnc.2015.03.007", doi_ce)) %>%
  mutate(doi_ce = str_replace(doi_ce, "http://www.bioone.org/doi/abs/", "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, "https://link.springer.com/article/", "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, "https://onlinelibrary.wiley.com/doi/abs/", "")) %>%  
  mutate(doi_ce = str_replace(doi_ce, "NA", NA_character_)) %>% 
  mutate(doi_url = str_replace(url, fixed(journal_doi_prefix[1]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[2]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[3]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[4]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[5]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[6]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[7]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[8]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[9]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[10]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[11]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[12]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[13]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[14]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[15]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[16]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[17]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[18]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[19]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[20]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[21]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[22]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[23]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[24]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[25]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[26]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[27]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[28]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[29]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[30]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[31]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[1], "")) %>%
  mutate(doi_url = str_replace(doi_url, doi_prefix[2], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[3], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[4], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[5], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[6], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[7], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[8], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[9], "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/abstract", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/full", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, ".pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2F", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2f", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&type=printable"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=e7e28a9bcf2a253ad4cdbc1c807581c1"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=69d21e627f92cd4b6f3c9837c45d6f2c"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=1af9d56b08f7404744b5e497fda4cd24"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=5c317266eef42c4e3e99d4ca26b2db29"), "")) -> cedat_study02
 
# birds
cebird %>%
  mutate(url = str_trim(url)) %>%
  mutate(doi_url = str_replace(url, fixed(journal_doi_prefix[1]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[2]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[3]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[4]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[5]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[6]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[7]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[8]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[9]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[10]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[11]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[12]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[13]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[14]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[15]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[16]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[17]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[18]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[19]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[20]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[21]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[22]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[23]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[24]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[25]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[26]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[27]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[28]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[29]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[30]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[31]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[1], "")) %>%
  mutate(doi_url = str_replace(doi_url, doi_prefix[2], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[3], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[4], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[5], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[6], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[7], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[8], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[9], "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/abstract", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/full", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, ".pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2F", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2f", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&type=printable"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=e7e28a9bcf2a253ad4cdbc1c807581c1"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=69d21e627f92cd4b6f3c9837c45d6f2c"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=1af9d56b08f7404744b5e497fda4cd24"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=5c317266eef42c4e3e99d4ca26b2db29"), "")) -> cebird02

# Manually include some missing dois
write.csv(cebird02, "data/cebird.csv", row.names = FALSE)
cebird03 <- read.csv("data/cebird.csv")

cedat_study02 %>% 
  mutate(url_flag = ifelse(str_detect(doi_url, "http"), 1, 0), 
         wos_flag = ifelse(str_detect(doi_url, "ISI"), 1, 0)) %>% 
  mutate(doi_url = ifelse(url_flag==1 | wos_flag==1, NA_character_, doi_url)) %>% 
  mutate(doi_clean = coalesce(doi_ce, doi_url)) %>% 
  filter(!is.na(doi_clean)) -> cedat_tidy
sum(cedat_tidy$url_flag) # 0
cedat_tidy %>% filter(!is.na(doi_clean)) %>% nrow() # 795

cebird03 %>% 
  mutate(url_flag = ifelse(str_detect(doi_url, "http"), 1, 0), 
         www_flag = ifelse(str_detect(doi_url, "www"), 1, 0), 
         wos_flag = ifelse(str_detect(doi_url, "ISI"), 1, 0)) %>% 
  mutate(doi_url = ifelse(url_flag==1 |www_flag==1 |wos_flag==1, NA_character_, doi_url)) %>% 
  mutate(doi_clean = doi_url) %>% 
  filter(!is.na(doi_clean)) -> cebird_tidy

# Now science direct (36 articles)
library(rscopus) # via UNIFAP
cedat_study02 %>% 
  mutate(sci_flag = ifelse(str_detect(doi_url, "pii"), 1, 0)) %>%
filter(sci_flag ==1) %>% pull(doi_url)

cedat_study02 %>% 
  mutate(sci_flag = ifelse(str_detect(doi_url, "pii"), 1, 0)) %>%
filter(is.na(doi_ce) ,sci_flag ==1) %>% 
  separate(doi_url, into=c("a", "id_pii"), sep="pii/") %>% 
  select(study.id, id_pii) -> els_toget

```

Now join with Abstracts from WOS search. 117 join at first attempt. 
127 after more dois tidied.
Test and develop searches......
```{r join-abstracts}
alt_all <- readRDS("data/alt_all.rds")
alt_all %>% 
  filter(!is.na(DI), PY>=2011) %>% 
  distinct() %>%
  group_by(SO) %>% summarise(count_articles = n()) %>% 
  arrange(desc(count_articles))
# Invalid doi
cedat_tidy %>% 
  separate(doi_clean, into=c("doi_clean", NA), sep=" ") %>%
  left_join(alt_all %>% select(DI, AB, SO, TC, altmetric), 
            by=c("doi_clean"="DI")) %>% 
  mutate(flag_na = ifelse(is.na(TC),1,0)) %>% 
  filter(! doi_clean =="10.7325/7") %>% 
  mutate(flag_search = if_else(is.na(SO),0,1), 
         flag_ce = 1) -> cedat_alt
# check doi is unique (max should be 1)
cedat_alt %>% 
  group_by(doi_clean) %>% summarise(count_articles = n()) %>% 
  arrange(desc(count_articles)) %>% pull(count_articles) %>% max()

cedat_alt %>% 
  group_by(SO) %>% summarise(count_na = sum(flag_na)) %>% 
  arrange(desc(count_na))

cedat_alt %>% 
  filter(!is.na(SO)) #127
# Find CE articles missed by my search
cedat_alt %>%
  filter(!is.na(journal.name)) %>%
  group_by(journal.name) %>% 
    summarise(count_articles = length(unique(study.id)), 
              count_both = sum(flag_search)) %>% 
  arrange(desc(count_articles))

```

Add Journals and Abstracts using crossref and pubmed.
```{r abstracts-crossref}
# crossref
# Politely import Abstracts 
# 1) helper functions
source("R/safe_cr_cn.R")
source("R/get_cr_cn.R")
source("R/safe_abstracts.R")
source("R/get_abstracts.R")
# Journals to go with dois
out_crossref <- rcrossref::cr_cn(dois = "10.1016/j.biocon.2015.08.034", 
                                 format = "bibentry")
# Journal names (so can double check CE)
j01 <- plyr::ddply(cedat_alt[1:200, ], .(doi_clean), .fun = get_cr_cn)
j02 <- plyr::ddply(cedat_alt[201:400, ], .(doi_clean), .fun = get_cr_cn)
j03 <- plyr::ddply(cedat_alt[401:600, ], .(doi_clean), .fun = get_cr_cn)
j04 <- plyr::ddply(cedat_alt[601:795, ], .(doi_clean), .fun = get_cr_cn) 

# stick together
bind_rows(j01, j02, j03, j04) %>% 
  mutate(journal = str_replace_all(journal, "[^[:alnum:]]", " ")) %>% 
  mutate(journal = str_replace(journal, "amp  mathsemicolon", "")) %>% 
  mutate(journal = str_replace(journal, "Journal du Conseil", "")) %>%
  mutate(journal = str_to_upper(str_squish(str_trim(journal)))) -> journal_names
# check doi is unique (max should be 1)
cedat_alt %>% 
  group_by(doi_clean) %>% summarise(count_journals = n()) %>% 
  arrange(desc(count_journals)) %>% pull(count_journals) %>% max()
# 9 missing with doi
cedat_alt %>% left_join(journal_names) %>% filter(is.na(journal))
# Abstracts
"10.1111/acv.12189"
t <- safe_abstracts(doi="10.1111/acv.12189")
ab01 <- plyr::adply(cedat_alt[1:200, ], .margins = 1, .fun = get_abstracts)
ab02 <- plyr::adply(cedat_alt[201:400, ], .margins = 1, .fun = get_abstracts)
ab03 <- plyr::adply(cedat_alt[401:600, ], .margins = 1, .fun = get_abstracts)
ab04 <- plyr::adply(cedat_alt[601:795, ], .margins = 1, .fun = get_abstracts)

# stick together
bind_rows(ab01, ab02, ab03, ab04) %>% 
  mutate(ab_text = 
           str_to_upper(str_trim((str_replace(ab_text, "Abstract", ""))))) %>% 
  mutate(ab_clean = coalesce(AB, ab_text)) -> abs_crossref
# 233 with Abstracts
abs_crossref %>% 
 filter(!is.na(ab_clean))

#Pubmed
#library(pubmedR) #Error: HTTP failure: 400
library(easyPubMed)
library(bibliometrix)
#My API: ff5578bfd85d5a8281f602b4b6b9f1cc7e08
api_key <- "ff5578bfd85d5a8281f602b4b6b9f1cc7e08"
query <- "10.1016/j.biocon.2015.08.034[DOI]"
query2 <- "10.1111/acv.12189[DOI]"
my_query <- safe_pubmedid(query2, 
                          api_key ="ff5578bfd85d5a8281f602b4b6b9f1cc7e08")
# easypubmed
source("R/safe_pubmedid.R")
source("R/get_pubmedids.R")
pubmed_abs01 <- plyr::ddply(cedat_alt[1:100, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs02 <- plyr::ddply(cedat_alt[101:200, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs03 <- plyr::ddply(cedat_alt[201:400, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs04 <- plyr::ddply(cedat_alt[401:450, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs05 <- plyr::ddply(cedat_alt[451:475, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs06 <- plyr::ddply(cedat_alt[476:500, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs07 <- plyr::ddply(cedat_alt[501:550, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs08 <- plyr::ddply(cedat_alt[551:600, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs09 <- plyr::ddply(cedat_alt[601:650, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs10 <- plyr::ddply(cedat_alt[651:700, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs11 <- plyr::ddply(cedat_alt[701:750, ], .(doi_clean), .fun = get_pubmedids) 
pubmed_abs12 <- plyr::ddply(cedat_alt[751:795, ], .(doi_clean), .fun = get_pubmedids)
# stick together 795 to 775 with distinct
bind_rows(pubmed_abs01, pubmed_abs02, pubmed_abs03, pubmed_abs04, pubmed_abs05, 
          pubmed_abs06, pubmed_abs07, pubmed_abs08, pubmed_abs09, pubmed_abs10, 
          pubmed_abs11, pubmed_abs12) %>%   distinct() %>% 
  mutate(ab_pubmed = str_to_upper(str_trim(ab_pubmed))) -> abs_pub
# birds 
j05 <- plyr::ddply(cebird_tidy, .(doi_clean), .fun = get_cr_cn) 
ab05 <- plyr::adply(cebird_tidy, .margins = 1, .fun = get_abstracts)
pubmed_abs13 <- plyr::ddply(cebird_tidy, .(doi_clean), .fun = get_pubmedids)
# stick together. Only 2 Abstracts.
cebird_tidy %>% left_join(ab05) %>% left_join(pubmed_abs13) -> abs_brids
# Dimensions
library(dimensionsR)
token <- dsAuth(username = "darren.norris@unifap.br", password = "Dimensions@78")

# rscopus
# DOI("doi1") OR ("doi2") OR...

abs_crossref %>% left_join(abs_pub) %>% 
  mutate(ab_clean = str_squish(str_trim(coalesce(AB, ab_pubmed, ab_text)))) %>% 
  left_join(journal_names) %>% 
  mutate(journal_name = coalesce(SO, journal)) -> abs_all
# 280 Abstracts
abs_all %>% 
  filter(!is.na(ab_clean)) 
# which journals have most missing abstracts
abs_all %>% 
  filter(is.na(ab_clean)) %>% 
  group_by(journal_name) %>% 
  summarise(acount = n()) %>% arrange(desc(acount))
#Unclear why missing Abstracts from same journal
abs_all %>% 
  filter(is.na(ab_clean)) %>%
  filter(journal_name =="ANIMAL CONSERVATION")

#Export. Need to manually clean few Abstracts starting with refs.
cedat_alt %>% pull(study.id) -> sids
cedat_studies %>% 
  left_join(abs_all %>% filter(study.id %in% sids) %>% 
              select(study.id, doi_clean, ab_clean)) %>% 
  mutate(doi_url = if_else(is.na(doi_clean), doi_clean, paste("https://doi.org/", doi_clean, sep=""))) %>% 
  select(study.id, publication.year,publication.title, journal.name, doi, url, doi_clean, doi_url, ab_clean, intervention_count) -> out_cedat_dois
# 280 Abstracts
out_cedat_dois %>% filter(!is.na(ab_clean)) %>% nrow()
# Find which to update/tidy more
out_cedat_dois %>% 
  filter(!is.na(journal.name)) %>%
  mutate(flag_na_doi = if_else(is.na(doi_clean),1,0), 
         flag_na_ab = if_else(is.na(doi_clean),1,0)) %>% 
  group_by(journal.name) %>% 
  summarise(tot_articles = length(unique(study.id)), 
            na_doi = sum(flag_na_doi), 
            na_ab = sum(flag_na_ab)) %>% 
  arrange(desc(na_doi)) %>% 
  filter(na_doi > 0, na_doi < tot_articles) -> cedat_tocheck
#compare with original data
out_cedat_dois %>% 
  filter(!is.na(journal.name), !is.na(doi_clean)) %>% 
  group_by(journal.name) %>% summarise(article_count = n()) %>% 
  arrange(desc(article_count))

out_cedat_dois  %>% 
  write.csv("data/cedat_cleandois.csv", row.names = FALSE) 
  
```

Save workspace.
```{r }
save.image("~/Articles/2024_Norris_trytofail/hey-jude/data/ce_abstracts.RData")
```

