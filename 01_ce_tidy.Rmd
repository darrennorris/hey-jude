---
title: "01_development"
author: "Darren Norris"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    toc_depth: 3
    fig_caption: yes
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    number_sections: yes
    extra_dependencies: flafter
    highlight: tango
    includes:
      in_header: preamble.txe
always_allow_html: yes
urlcolor: blue
toc-title: Contents
header-includes:
  - \counterwithin{figure}{section}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE, collapse = TRUE,
  comment = "#>" 
  )
def_hook <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  out <- def_hook(x, options)
  return(paste("\\begin{framed}\\begin{verbatim}", x, "\\end{verbatim}\\end{framed}", collapse = "\n"))
})
```

\newpage{}

## Packages
```{r load-packages, warning=FALSE, message=FALSE}
# Data processing and presentation
library(plyr) # plyr before tidyverse
library(tidyverse)
library(stringr)
library(textclean)
library(readxl)
library(gridExtra)
library(magrittr)
library(rcrossref)

```

Load data
```{r load-data}
# Has Conservation Evidence from the following synopses Amphibian, Bat, Bird, Management of captive animals, marine and freshwater mammals, marine fish, primates, reptiles, terrestrial mammals
cedat <- read_excel('data/studydat_fordarrenn_24_02_2023.xlsx')
cedat %>% 
  # with 2011 lose 97 bird studies
  filter(publication.year>=2011) %>%
  group_by(synopsis.name) %>% 
  summarise(study_count = length(unique(study.id)))

cedat %>% 
  filter(publication.year>=2011) %>%
  # 1094 articles
  group_by(study.id, publication.year, publication.title, 
           journal.name,doi, url) %>% 
  summarise(intervention_count = n()) %>% 
  ungroup() -> cedat_studies
cedat_studies %>% nrow() #1094
# 35 not journals
cedat_studies %>% 
  filter(is.na(journal.name)) %>% nrow()
# 834 dois are NA
cedat_studies %>% 
  filter(is.na(doi)) %>% nrow()
# 260 dois not NA
cedat_studies %>% 
  filter(!is.na(doi)) %>% nrow()

```

Get dois
```{r get-dois}
# Create new doi column to join with bibliometrics
# clean out prefixes
doi_prefix <- c("http://dx.doi.org/DOI:", "http://dx.doi.org/doi:", 
"http://dx.doi.org/", "https://dx.doi.org/DOI:", "https://dx.doi.org/doi:", 
"https://dx.doi.org/", 
"DOI:", "http://doi.org/", "https://doi.org/")
doi_prefix_string <- paste(doi_prefix,collapse="")
#scopus seperator "&"
journal_doi_prefix <- c( "http://www.asmjournals.org/doi/abs/",
"http://link.springer.com/article/",  
"https://link.springer.com/chapter/", 
"https://link.springer.com/content/pdf/",
"http://www.bioone.org/doi/abs/", "http://www.karger.com/DOI/", 
"http://www.tandfonline.com/doi/abs/", 
"https://besjournals.onlinelibrary.wiley.com/doi/epdf/",
"https://besjournals.onlinelibrary.wiley.com/doi/abs/", 
"https://journals.plos.org/plosone/article/file?id=", 
"https://journals.plos.org/plosone/article?id=", 
"http://journals.sagepub.com/doi/abs/",
"https://link.springer.com/article/", 
"https://www.frontiersin.org/articles/",
"https://onlinelibrary.wiley.com/doi/epdf/",
"https://onlinelibrary.wiley.com/doi/pdf/",
"https://onlinelibrary.wiley.com/doi/abs/", 
"https://onlinelibrary.wiley.com/doi/full/", 
"https://onlinelibrary.wiley.com/doi/",
"http://onlinelibrary.wiley.com/doi/", 
"https://royalsocietypublishing.org/doi/pdf/",
"https://wildlife.onlinelibrary.wiley.com/doi/abs/", 
"https://wildlife.onlinelibrary.wiley.com/doi/pdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/epdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/pdf/",
"https://zslpublications.onlinelibrary.wiley.com/doi/", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997426723&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951076741&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959282517&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940942773&doi=", 
"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949952613&doi="
)

cedat_studies %>% 
  mutate(doi = str_trim(doi), 
         url = str_trim(url)) %>%
  mutate(doi_ce = str_replace(doi, doi_prefix[1], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[2], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[3], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[4], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[5], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[6], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[7], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[8], "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, doi_prefix[9], "")) %>% 
  mutate(doi_ce = if_else(study.id ==7943 ,"10.1016/j.jnc.2015.03.007", doi_ce)) %>%
  mutate(doi_ce = str_replace(doi_ce, "http://www.bioone.org/doi/abs/", "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, "https://link.springer.com/article/", "")) %>% 
  mutate(doi_ce = str_replace(doi_ce, "https://onlinelibrary.wiley.com/doi/abs/", "")) %>%  
  mutate(doi_ce = str_replace(doi_ce, "NA", NA_character_)) %>% 
  mutate(doi_url = str_replace(url, fixed(journal_doi_prefix[1]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[2]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[3]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[4]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[5]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[6]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[7]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[8]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[9]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[10]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[11]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[12]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[13]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[14]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[15]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[16]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[17]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[18]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[19]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[20]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[21]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[22]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[23]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[24]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[25]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[26]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[27]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[28]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[29]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[30]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed(journal_doi_prefix[31]), "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[1], "")) %>%
  mutate(doi_url = str_replace(doi_url, doi_prefix[2], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[3], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[4], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[5], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[6], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[7], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[8], "")) %>% 
  mutate(doi_url = str_replace(doi_url, doi_prefix[9], "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/abstract", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/full", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "/pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, ".pdf", "")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2F", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, "%2f", "/")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&type=printable"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=e7e28a9bcf2a253ad4cdbc1c807581c1"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=69d21e627f92cd4b6f3c9837c45d6f2c"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=1af9d56b08f7404744b5e497fda4cd24"), "")) %>% 
  mutate(doi_url = str_replace(doi_url, fixed("&partnerID=40&md5=5c317266eef42c4e3e99d4ca26b2db29"), "")) -> cedat_study02
 
cedat_study02 %>% filter(journal.name=="Biological Conservation", is.na(doi))

cedat_study02 %>% 
  mutate(url_flag = ifelse(str_detect(doi_url, "http"), 1, 0), 
         wos_flag = ifelse(str_detect(doi_url, "ISI"), 1, 0)) %>% 
  mutate(doi_url = ifelse(url_flag==1 | wos_flag==1, NA_character_, doi_url)) %>% 
  mutate(doi_clean = coalesce(doi_ce, doi_url)) %>% 
  filter(!is.na(doi_clean)) -> cedat_tidy
sum(cedat_tidy$url_flag) # 149
cedat_tidy %>% filter(!is.na(doi_clean)) %>% nrow() # 780


# Now science direct (36 articles)
library(rscopus) # via UNIFAP
cedat_study02 %>% 
  mutate(sci_flag = ifelse(str_detect(doi_url, "pii"), 1, 0)) %>%
filter(sci_flag ==1) %>% pull(doi_url)

cedat_study02 %>% 
  mutate(sci_flag = ifelse(str_detect(doi_url, "pii"), 1, 0)) %>%
filter(is.na(doi_ce) ,sci_flag ==1) %>% 
  separate(doi_url, into=c("a", "id_pii"), sep="pii/") %>% 
  select(study.id, id_pii) -> els_toget

```

Now join with Abstracts from WOS search. 117 join at first attempt.
Test and develop searches......
```{r join-abstracts}
alt_all <- readRDS("data/alt_all.rds")
# Invalid doi
cedat_alt %>% filter(doi_clean=="10.7325/7")
cedat_tidy %>% 
  left_join(alt_all %>% select(DI, AB, SO, TC, altmetric), 
            by=c("doi_clean"="DI")) %>% 
  mutate(flag_na = ifelse(is.na(TC),1,0)) %>% 
  filter(! doi_clean =="10.7325/7") -> cedat_alt

cedat_alt %>% 
  group_by(SO) %>% summarise(count_na = sum(flag_na)) %>% 
  arrange(desc(count_na))

cedat_alt %>% 
  filter(!is.na(SO)) #122


```

Add Journals and Abstracts using crossref and pubmed.
```{r abstracts-crossref}
# crossref
# Politely import Abstracts 
# 1) helper functions
source("R/safe_cr_cn.R")
source("R/get_cr_cn.R")
source("R/safe_abstracts.R")
source("R/get_abstracts.R")
# Journals to go with dois
out_crossref <- rcrossref::cr_cn(dois = "10.1016/j.biocon.2015.08.034", 
                                 format = "bibentry")
# Journal names 
j01 <- plyr::ddply(cedat_alt[1:200, ], .(doi_clean), .fun = get_cr_cn)
j02 <- plyr::ddply(cedat_alt[201:400, ], .(doi_clean), .fun = get_cr_cn)
j03 <- plyr::ddply(cedat_alt[401:600, ], .(doi_clean), .fun = get_cr_cn)
j04 <- plyr::ddply(cedat_alt[601:771, ], .(doi_clean), .fun = get_cr_cn) 
bind_rows(j01, j02, j03, j04) %>% 
  mutate(journal = str_replace_all(journal, "[^[:alnum:]]", " ")) %>% 
  mutate(journal = str_replace(journal, "amp  mathsemicolon", "")) %>% 
  mutate(journal = str_replace(journal, "Journal du Conseil", "")) %>%
  mutate(journal = str_to_upper(str_squish(str_trim(journal)))) -> journal_names

   
# Abstracts
"10.1111/acv.12189"
t <- safe_abstracts(doi="10.1111/acv.12189")
ab01 <- plyr::adply(cedat_alt[1:200, ], .margins = 1, .fun = get_abstracts)
ab02 <- plyr::adply(cedat_alt[201:400, ], .margins = 1, .fun = get_abstracts)
ab03 <- plyr::adply(cedat_alt[401:600, ], .margins = 1, .fun = get_abstracts)
ab04 <- plyr::adply(cedat_alt[601:771, ], .margins = 1, .fun = get_abstracts)
#join
bind_rows(ab01, ab02, ab03, ab04) %>% 
  mutate(ab_text = 
           str_to_upper(str_trim((str_replace(ab_text, "Abstract", ""))))) %>% 
  mutate(ab_clean = coalesce(AB, ab_text)) -> abs_crossref
# 223 with Abstracts
abs_crossref %>% 
 filter(!is.na(ab_clean))

#Pubmed
#library(pubmedR) #Error: HTTP failure: 400
library(easyPubMed)
library(bibliometrix)
#My API: ff5578bfd85d5a8281f602b4b6b9f1cc7e08
api_key <- "ff5578bfd85d5a8281f602b4b6b9f1cc7e08"
query <- "10.1016/j.biocon.2015.08.034[DOI]"
query2 <- "10.1111/acv.12189[DOI]"
my_query <- safe_pubmedid(query2, 
                          api_key ="ff5578bfd85d5a8281f602b4b6b9f1cc7e08")
# easypubmed
source("R/safe_pubmedid.R")
source("R/get_pubmedids.R")
pubmed_abs01 <- plyr::ddply(cedat_alt[1:100, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs02 <- plyr::ddply(cedat_alt[101:200, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs03 <- plyr::ddply(cedat_alt[201:300, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs04 <- plyr::ddply(cedat_alt[301:400, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs05 <- plyr::ddply(cedat_alt[401:450, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs06 <- plyr::ddply(cedat_alt[451:475, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs07 <- plyr::ddply(cedat_alt[476:480, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs08 <- plyr::ddply(cedat_alt[481:490, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs09 <- plyr::ddply(cedat_alt[491:500, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs10 <- plyr::ddply(cedat_alt[501:600, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs11 <- plyr::ddply(cedat_alt[601:700, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs12 <- plyr::ddply(cedat_alt[701:730, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs13 <- plyr::ddply(cedat_alt[731:760, ], .(doi_clean), .fun = get_pubmedids)
pubmed_abs14 <- plyr::ddply(cedat_alt[761:772, ], .(doi_clean), .fun = get_pubmedids)

bind_rows(pubmed_abs01, pubmed_abs02, pubmed_abs03, pubmed_abs04, pubmed_abs05, 
          pubmed_abs06, pubmed_abs07, pubmed_abs08, pubmed_abs09, pubmed_abs10, 
          pubmed_abs11, pubmed_abs12, pubmed_abs13, pubmed_abs14) %>% 
  distinct() %>% 
  mutate(ab_pubmed = str_to_upper(str_trim(ab_pubmed))) -> abs_pub

# Dimensions
library(dimensionsR)
token <- dsAuth(username = "darren.norris@unifap.br", password = "Dimensions@78")

# rscopus
# DOI("doi1") OR ("doi2") OR...

abs_crossref %>% left_join(abs_pub) %>% 
  mutate(ab_clean = str_squish(str_trim(coalesce(AB, ab_pubmed, ab_text)))) %>% 
  left_join(journal_names) %>% 
  mutate(journal_name = coalesce(SO, journal)) -> abs_all
# 266 Abstracts
abs_all %>% 
  filter(!is.na(ab_clean)) 
# which journals have most missing abstracts
abs_all %>% 
  filter(is.na(ab_clean)) %>% 
  group_by(journal_name) %>% 
  summarise(acount = n()) %>% arrange(desc(acount))
#Unclear why missing Abstracts from same journal
abs_all %>% 
  filter(is.na(ab_clean)) %>%
  filter(journal_name =="ANIMAL CONSERVATION")

#Export. Need to manually clean few Abstracts starting with refs.
cedat_alt %>% pull(study.id) -> sids
cedat_studies %>% 
  left_join(abs_all %>% filter(study.id %in% sids) %>% 
              select(study.id, doi_clean, ab_clean)) %>% 
  mutate(doi_url = if_else(is.na(doi_clean), doi_clean, paste("https://doi.org/", doi_clean, sep=""))) %>% 
  select(study.id, publication.year,publication.title, journal.name, doi, url, doi_clean, doi_url, ab_clean, intervention_count) -> out_cedat_dois
# 266 Abstracts
out_cedat_dois %>% filter(!is.na(ab_clean)) %>% nrow()
# Find which to update/tidy more
out_cedat_dois %>% 
  filter(!is.na(journal.name)) %>%
  mutate(flag_na_doi = if_else(is.na(doi_clean),1,0), 
         flag_na_ab = if_else(is.na(doi_clean),1,0)) %>% 
  group_by(journal.name) %>% 
  summarise(tot_articles = length(unique(study.id)), 
            na_doi = sum(flag_na_doi), 
            na_ab = sum(flag_na_ab)) %>% 
  arrange(desc(na_doi)) %>% 
  filter(na_doi > 0, na_doi < tot_articles) -> cedat_tocheck

out_cedat_dois  %>% 
  write.csv("data/cedat_cleandois.csv", row.names = FALSE) 
  
```

